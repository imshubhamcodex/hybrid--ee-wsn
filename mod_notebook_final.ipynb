{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "CezAKBDH7XFA",
      "metadata": {
        "id": "CezAKBDH7XFA"
      },
      "source": [
        "# Energy-Efficient Wireless Sensor Network (EE-WSN) Simulation\n",
        "\n",
        "This notebook compares 6 clustering algorithms for WSN energy optimization:\n",
        "1. **RLHC_PROPOSED** - Novel RL-driven hybrid clustering method\n",
        "2. **LEACH_BASELINE** - Low-Energy Adaptive Clustering Hierarchy\n",
        "3. **DEEC_BASELINE** - Distributed Energy-Efficient Clustering\n",
        "4. **FUZZY_C_MEANS_BASELINE** - Fuzzy C-Means clustering\n",
        "5. **PSO_BASELINE** - Particle Swarm Optimization with Genetic Algorithm\n",
        "6. **ACO_BASELINE** - Ant Colony Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WhFXxyWV7XFC",
      "metadata": {
        "id": "WhFXxyWV7XFC"
      },
      "source": [
        "## 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fgdDQfzq7XFC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fgdDQfzq7XFC",
        "outputId": "dd3646b1-094e-4a2e-c5f8-0aa08f368632"
      },
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "# !pip install numpy matplotlib pandas scikit-fuzzy\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import heapq\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "from collections import defaultdict\n",
        "import skfuzzy as fuzz\n",
        "from IPython.display import HTML\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "print('All packages imported successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6R3gRrI17XFE",
      "metadata": {
        "id": "6R3gRrI17XFE"
      },
      "source": [
        "## 2. Configuration Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-2o0yc3Q7XFE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2o0yc3Q7XFE",
        "outputId": "e5baef19-6aaf-42e2-df5f-056890e15985"
      },
      "outputs": [],
      "source": [
        "# Simulation Parameters\n",
        "AREA_SIZE = 1000  # meters L, B\n",
        "N_NODES = 150       # number of sensor nodes\n",
        "INIT_ENERGY = 2.0   # joules per node\n",
        "NUM_CLUSTERS = int(N_NODES * 0.1)\n",
        "ROUNDS = 1000\n",
        "PACKET_SIZE_BYTES = 128\n",
        "PACKET_SIZE_BITS = PACKET_SIZE_BYTES * 8\n",
        "N_HALF = N_NODES // 2\n",
        "SEED = 10\n",
        "SECTOR_ROWS = 3\n",
        "SECTOR_COLS = 3\n",
        "BASE_STATION_FIXED = (AREA_SIZE / 2, AREA_SIZE / 2)\n",
        "BS_TRAJECTORY = []\n",
        "\n",
        "# Routing Parameters\n",
        "GLOBAL_ROUTING_INFO = {} # Holds RLHC routing info\n",
        "ENABLE_MULTI_HOP = True\n",
        "\n",
        "# Base/Sink Mobility\n",
        "BS_MODE = \"mobile_circle\"   # fixed, mobile_circle, mobile_random\n",
        "\n",
        "if BS_MODE == \"mobile_circle\":\n",
        "    ROUNDS = 500\n",
        "    EFFECTIVE_ROUNDS = 275  # BS Complete one circle in these many rounds\n",
        "elif BS_MODE == \"mobile_random\":\n",
        "    ROUNDS = 150\n",
        "\n",
        "\n",
        "# Radio Energy Model (First-order)\n",
        "E_ELEC = 50e-9  # J/bit (typical)\n",
        "EPS_FS = 10e-12  # J/bit/m^2 (free space)\n",
        "EPS_MP = 0.0013e-12  # J/bit/m^4 (multipath)\n",
        "D0 = math.sqrt(EPS_FS / EPS_MP) if EPS_MP > 0 else 87.7  # threshold\n",
        "\n",
        "\n",
        "# DEEC Parameters\n",
        "P_OPT = NUM_CLUSTERS / N_NODES  # desired CH fraction\n",
        "MAX_CH = NUM_CLUSTERS\n",
        "M_FRACTION_ADV = 0.1     # fraction of advanced nodes (e.g. 10%) Heterogeneous\n",
        "A_ADV_ENERGY   = 1.0     # advanced nodes have (1 + a)*E0 energy, here 2*E0\n",
        "E0 = INIT_ENERGY         # you already have INIT_ENERGY\n",
        "\n",
        "\n",
        "# RL Parameters (tabular Q-learning)\n",
        "STATE_BINS_E = 4       # energy levels\n",
        "STATE_BINS_LOAD = 3    # channel load levels\n",
        "STATE_BINS_PDR = 3     # packet delivery ratio levels\n",
        "EPSILON = 1.0\n",
        "EPS_MIN = 0.05         # minimum epsilon\n",
        "EPS_DECAY = 0.995      # epsilon decay per episode\n",
        "ALPHA = 0.1            # learning rate\n",
        "GAMMA = 0.95           # discount factor\n",
        "\n",
        "# RL Actions\n",
        "A_NOOP = 0          # no operation\n",
        "A_REASSIGN_FEW = 1  # reassign few nodes\n",
        "A_SWITCH_CH = 2     # switch cluster head\n",
        "A_REDUCE_TX = 3     # reduce transmission power\n",
        "A_INCREASE_TX = 4   # increase transmission power\n",
        "ACTIONS = [A_NOOP, A_REASSIGN_FEW, A_SWITCH_CH, A_REDUCE_TX, A_INCREASE_TX]\n",
        "\n",
        "\n",
        "# PSO parameters\n",
        "W = 0.9       # inertia weight\n",
        "C1 = 1.8      # cognitive weight\n",
        "C2 = 1.8      # social weight\n",
        "PSO_POP = 30  # number of particles\n",
        "GA_GEN = 10    # number of GA generations per round\n",
        "\n",
        "\n",
        "# ACO parameters\n",
        "ACO_ALPHA = 1.0      # pheromone importance\n",
        "ACO_BETA = 3.0       # heuristic importance\n",
        "RHO = 0.3            # pheromone evaporation\n",
        "ACO_Q = 50          # pheromone constant\n",
        "ANTS = NUM_CLUSTERS  # number of ants\n",
        "\n",
        "\n",
        "print('Configuration loaded successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c-9KSF_B7XFE",
      "metadata": {
        "id": "c-9KSF_B7XFE"
      },
      "source": [
        "## 3. Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "URhByZbi7XFF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URhByZbi7XFF",
        "outputId": "028d9c71-367d-49a2-a024-d1b374e6f1fd"
      },
      "outputs": [],
      "source": [
        "def energy_tx(bits, d):\n",
        "    \"\"\"Transmission energy for bits over distance d (meters).\"\"\"\n",
        "    if d < D0:\n",
        "        return bits * E_ELEC + bits * EPS_FS * (d**2)\n",
        "    else:\n",
        "        return bits * E_ELEC + bits * EPS_MP * (d**4)\n",
        "\n",
        "def energy_rx(bits):\n",
        "    return bits * E_ELEC\n",
        "\n",
        "def distance(a, b):\n",
        "    return math.hypot(a[0]-b[0], a[1]-b[1]) # Find 2D Euclidean Distance\n",
        "\n",
        "def discretize(value, bins):\n",
        "    return int(np.digitize([value], bins=bins)[0])\n",
        "\n",
        "def build_bins():\n",
        "    # 3 load levels: low (<1.2), medium (1.2–1.5), high (>1.5) imbalance\n",
        "    load_bins = [1.2, 1.5]\n",
        "    # 3 PDR levels: low (<0.90), medium (0.90–0.97), high (>0.97) reliability\n",
        "    pdr_bins = [0.90, 0.97]\n",
        "    return load_bins, pdr_bins\n",
        "\n",
        "def state_from_metrics(avg_energy, cluster_sizes, pdr, LOAD_BINS, PDR_BINS):\n",
        "    norm_avg_e = avg_energy / INIT_ENERGY\n",
        "    e_bins = np.linspace(0, 1, STATE_BINS_E + 1)[1:-1]\n",
        "    e_bucket = discretize(norm_avg_e, bins=e_bins)\n",
        "\n",
        "    if len(cluster_sizes) == 0:\n",
        "        load_ratio = 1.0\n",
        "    else:\n",
        "        load_ratio = max(cluster_sizes) / (np.mean(cluster_sizes) + 1e-12)\n",
        "\n",
        "    load_bucket = discretize(load_ratio, bins=LOAD_BINS)\n",
        "    pdr_bucket = discretize(pdr, bins=PDR_BINS)\n",
        "    return (e_bucket, load_bucket, pdr_bucket)\n",
        "\n",
        "def measure_metrics(nodes_energy, clusters, chs, successful_packets, total_packets):\n",
        "    alive = int(np.sum(nodes_energy > 0))\n",
        "    avg_e = float(np.mean(nodes_energy))\n",
        "    pdr = successful_packets / (total_packets + 1e-12)\n",
        "    cluster_sizes = [len(c) for c in clusters] if clusters else []\n",
        "    return avg_e, pdr, alive, cluster_sizes\n",
        "\n",
        "def initialize_heterogeneous_energies():\n",
        "    \"\"\"\n",
        "    Initialize node energies for 2-level heterogeneous DEEC such that\n",
        "    the *total* initial energy equals N_NODES * INIT_ENERGY.\n",
        "\n",
        "    - Normal nodes: E0_eff\n",
        "    - Advanced nodes: (1 + A_ADV_ENERGY) * E0_eff\n",
        "    Fraction of advanced nodes: M_FRACTION_ADV\n",
        "    \"\"\"\n",
        "\n",
        "    E0_eff = INIT_ENERGY / (1.0 + A_ADV_ENERGY * M_FRACTION_ADV)\n",
        "\n",
        "    nodes_energy = np.array([E0_eff] * N_NODES, dtype=float)\n",
        "    is_advanced = np.zeros(N_NODES, dtype=bool)\n",
        "\n",
        "    num_adv = int(M_FRACTION_ADV * N_NODES)\n",
        "    if num_adv > 0:\n",
        "        adv_indices = np.random.choice(N_NODES, size=num_adv, replace=False)\n",
        "        is_advanced[adv_indices] = True\n",
        "        nodes_energy[adv_indices] = (1.0 + A_ADV_ENERGY) * E0_eff\n",
        "\n",
        "    return nodes_energy, is_advanced\n",
        "\n",
        "\n",
        "def assign_static_sectors(nodes_pos, area_size=1000, rows=3, cols=3):\n",
        "    \"\"\"\n",
        "    nodes_pos: list or array of shape (N_NODES, 2) with (x, y) positions\n",
        "    area_size: field is [0, area_size] x [0, area_size]\n",
        "    rows, cols: grid sectors (3x3 => 9 sectors)\n",
        "    returns: sector_ids[i] = sector index (0 .. rows*cols-1) for node i\n",
        "    \"\"\"\n",
        "    sector_ids = []\n",
        "    cell_w = area_size / cols   # ~333.33 m\n",
        "    cell_h = area_size / rows   # ~333.33 m\n",
        "\n",
        "    for (x, y) in nodes_pos:\n",
        "        # column index 0,1,2\n",
        "        c = int(x // cell_w)\n",
        "        if c >= cols:\n",
        "            c = cols - 1  # handle x == area_size\n",
        "\n",
        "        # row index 0,1,2\n",
        "        r = int(y // cell_h)\n",
        "        if r >= rows:\n",
        "            r = rows - 1  # handle y == area_size\n",
        "\n",
        "        # sector index: row-major\n",
        "        sector_idx = r * cols + c\n",
        "        sector_ids.append(sector_idx)\n",
        "\n",
        "    return np.array(sector_ids, dtype=int)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def get_bs_position(rnd=None):\n",
        "    global BS_TRAJECTORY\n",
        "\n",
        "    # -------- Scenario 1: fixed BS --------\n",
        "    if BS_MODE == \"fixed\":\n",
        "        return BASE_STATION_FIXED\n",
        "\n",
        "    # -------- Scenario 2: circular mobile BS (your current logic) --------\n",
        "    if BS_MODE == \"mobile_circle\":\n",
        "        if rnd is None:\n",
        "            if BS_TRAJECTORY:\n",
        "                return BS_TRAJECTORY[-1]\n",
        "            return BASE_STATION_FIXED\n",
        "\n",
        "        if len(BS_TRAJECTORY) >= rnd:\n",
        "            return BS_TRAJECTORY[rnd - 1]\n",
        "\n",
        "        cx, cy = AREA_SIZE / 2, AREA_SIZE / 2\n",
        "        radius_ratio = 0.3\n",
        "        radius = radius_ratio * AREA_SIZE\n",
        "\n",
        "        step = 2 * np.pi / EFFECTIVE_ROUNDS\n",
        "\n",
        "        for r in range(len(BS_TRAJECTORY) + 1, rnd + 1):\n",
        "            angle = step * r\n",
        "            x = cx + radius * np.cos(angle)\n",
        "            y = cy + radius * np.sin(angle)\n",
        "            BS_TRAJECTORY.append((x, y))\n",
        "\n",
        "        return BS_TRAJECTORY[rnd - 1]\n",
        "\n",
        "    # -------- Scenario 3: random position each round --------\n",
        "    if BS_MODE == \"mobile_random\":\n",
        "        if rnd is None:\n",
        "            # If no round given, return last if exists, else random\n",
        "            if BS_TRAJECTORY:\n",
        "                return BS_TRAJECTORY[-1]\n",
        "            x = np.random.uniform(0, AREA_SIZE)\n",
        "            y = np.random.uniform(0, AREA_SIZE)\n",
        "            BS_TRAJECTORY.append((x, y))\n",
        "            return BS_TRAJECTORY[-1]\n",
        "\n",
        "        # If already computed for this round, reuse it (to keep reproducibility)\n",
        "        if len(BS_TRAJECTORY) >= rnd:\n",
        "            return BS_TRAJECTORY[rnd - 1]\n",
        "\n",
        "        # Generate random positions up to 'rnd'\n",
        "        for r in range(len(BS_TRAJECTORY) + 1, rnd + 1):\n",
        "            x = np.random.uniform(0, AREA_SIZE)\n",
        "            y = np.random.uniform(0, AREA_SIZE)\n",
        "            BS_TRAJECTORY.append((x, y))\n",
        "\n",
        "        return BS_TRAJECTORY[rnd - 1]\n",
        "\n",
        "    # Fallback\n",
        "    return BASE_STATION_FIXED\n",
        "\n",
        "\n",
        "# To store routing info\n",
        "def init_method_routing(method_name):\n",
        "    if method_name not in GLOBAL_ROUTING_INFO:\n",
        "        GLOBAL_ROUTING_INFO[method_name] = {\n",
        "            \"chs\": {},\n",
        "            \"clusters\": {},\n",
        "            \"links\": {}\n",
        "        }\n",
        "\n",
        "def log_link(method_name, rnd, src, dst):\n",
        "    init_method_routing(method_name)\n",
        "    links = GLOBAL_ROUTING_INFO[method_name][\"links\"]\n",
        "    if rnd not in links:\n",
        "        links[rnd] = []\n",
        "    links[rnd].append((src, dst))\n",
        "\n",
        "def log_chs_and_clusters(method_name, rnd, chs, clusters):\n",
        "    \"\"\"\n",
        "    chs:      list of CH indices\n",
        "    clusters: list of lists (cluster membership)\n",
        "    \"\"\"\n",
        "    init_method_routing(method_name)\n",
        "    GLOBAL_ROUTING_INFO[method_name][\"chs\"][rnd] = list(chs)\n",
        "    GLOBAL_ROUTING_INFO[method_name][\"clusters\"][rnd] = [list(c) for c in clusters]\n",
        "\n",
        "\n",
        "print('Utility functions defined successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bvYj4ZDy7XFF",
      "metadata": {
        "id": "bvYj4ZDy7XFF"
      },
      "source": [
        "## 4. Communication Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BtK-bT9k7XFG",
      "metadata": {
        "id": "BtK-bT9k7XFG"
      },
      "outputs": [],
      "source": [
        "def radio_comm(clusters, chs, nodes_energy, nodes_pos, base_station, tx_power_factor, successful_packets=0, total_packets=0):\n",
        "    \"\"\"\n",
        "    End-to-end PDR:\n",
        "    - Each member node generates one packet.\n",
        "    - A packet is counted successful ONLY if it finally reaches the base station.\n",
        "    - Currently: single-hop CH->BS, but structure is compatible with future multi-hop.\n",
        "    \"\"\"\n",
        "\n",
        "    num_nodes = len(nodes_energy)\n",
        "\n",
        "    # Track which member packets reach their CH\n",
        "    # aggregated_packets[cidx] = number of member packets successfully stored at CH of cluster cidx\n",
        "    aggregated_packets = [0] * len(clusters)\n",
        "\n",
        "    # 1) Member -> CH phase\n",
        "    for cidx, members in enumerate(clusters):\n",
        "        ch = chs[cidx]\n",
        "\n",
        "        for node in members:\n",
        "            if nodes_energy[node] <= 0:\n",
        "                # dead node cannot generate/transmit a packet\n",
        "                continue\n",
        "\n",
        "            # Each (alive) member attempts to send ONE packet this round\n",
        "            total_packets += 1\n",
        "\n",
        "            # If CH is dead, packet cannot be delivered\n",
        "            if nodes_energy[ch] <= 0:\n",
        "                # Optional: decide whether node still spends energy trying to transmit\n",
        "                # For now, model that node tries to transmit even if CH is dead.\n",
        "                d = distance(nodes_pos[node], nodes_pos[ch])\n",
        "                etx = energy_tx(PACKET_SIZE_BITS, d) * tx_power_factor\n",
        "                if nodes_energy[node] >= etx:\n",
        "                    nodes_energy[node] -= etx\n",
        "                else:\n",
        "                    nodes_energy[node] = 0\n",
        "                # No success counted here (end-to-end)\n",
        "                continue\n",
        "\n",
        "            # CH is alive: simulate TX and RX\n",
        "            d = distance(nodes_pos[node], nodes_pos[ch])\n",
        "            etx = energy_tx(PACKET_SIZE_BITS, d) * tx_power_factor\n",
        "            erx = energy_rx(PACKET_SIZE_BITS)\n",
        "\n",
        "            # Check if both sides have enough energy for this communication\n",
        "            if nodes_energy[node] >= etx and nodes_energy[ch] >= erx:\n",
        "                nodes_energy[node] -= etx\n",
        "                nodes_energy[ch] -= erx\n",
        "                # Packet is now successfully at CH (but not yet at BS)\n",
        "                aggregated_packets[cidx] += 1\n",
        "            else:\n",
        "                # Not enough energy to complete TX/RX\n",
        "                if nodes_energy[node] >= etx:\n",
        "                    nodes_energy[node] -= etx   # node still spends energy trying\n",
        "                elif nodes_energy[node] > 0:\n",
        "                    nodes_energy[node] = 0\n",
        "\n",
        "                # Optional: you may also burn some CH energy even on failed RX\n",
        "                # if nodes_energy[ch] >= erx: nodes_energy[ch] -= erx\n",
        "\n",
        "                # Do NOT count success here (end-to-end)\n",
        "                continue\n",
        "\n",
        "    # 2) CH -> BS phase\n",
        "    # For end-to-end PDR, a member's packet is successful only if its CH\n",
        "    # successfully delivers to BS.\n",
        "    for cidx, ch in enumerate(chs):\n",
        "        cluster_packet_count = aggregated_packets[cidx]\n",
        "        if cluster_packet_count == 0:\n",
        "            # No data to send from this cluster\n",
        "            continue\n",
        "\n",
        "        if nodes_energy[ch] <= 0:\n",
        "            # CH dead: all aggregated packets from this cluster are lost\n",
        "            continue\n",
        "\n",
        "        # One transmission from CH to BS that represents all aggregated packets.\n",
        "        # If you want per-packet transmissions, you can loop cluster_packet_count times.\n",
        "        d = distance(nodes_pos[ch], base_station)\n",
        "        etx = energy_tx(PACKET_SIZE_BITS, d) * tx_power_factor\n",
        "\n",
        "        if nodes_energy[ch] >= etx:\n",
        "            # CH successfully sends aggregated data to BS\n",
        "            nodes_energy[ch] -= etx\n",
        "\n",
        "            # All aggregated member packets from this cluster are now delivered to BS\n",
        "            successful_packets += cluster_packet_count\n",
        "        else:\n",
        "            # Not enough energy to transmit => all packets from this cluster are lost\n",
        "            # Optional: still burn remaining energy attempt\n",
        "            nodes_energy[ch] = max(0, nodes_energy[ch] - etx)\n",
        "\n",
        "    return nodes_energy, successful_packets, total_packets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JBnH3uh87XFG",
      "metadata": {
        "id": "JBnH3uh87XFG"
      },
      "source": [
        "## 5. Proposed Method (RLHC) - Layer 1: DEEC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ufteka6u7XFH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufteka6u7XFH",
        "outputId": "47b8b91a-0f16-4812-e6c8-9bf1fdc59d7a"
      },
      "outputs": [],
      "source": [
        "def deec_select(nodes_energy, p_opt, min_chs=1, max_chs_factor=3.0):\n",
        "    \"\"\"\n",
        "    Layer-1: DEEC/DEECP-based CH selection.\n",
        "\n",
        "    - Uses P_i = p_opt * (E_i / E_avg)\n",
        "    - Heterogeneity is captured via nodes_energy (advanced nodes have higher E)\n",
        "    - Returns a set of CHs according to DEECP logic.\n",
        "    \"\"\"\n",
        "\n",
        "    n_nodes = len(nodes_energy)\n",
        "\n",
        "    E_avg = np.mean(nodes_energy)\n",
        "    if E_avg <= 0:\n",
        "        return []  # network dead\n",
        "\n",
        "    # DEECP probability\n",
        "    P_i = p_opt * (nodes_energy / E_avg)\n",
        "    P_i = np.clip(P_i, 0.0, 1.0)\n",
        "\n",
        "    # Probabilistic selection\n",
        "    candidates = []\n",
        "    for i, Pi in enumerate(P_i):\n",
        "        if random.random() <= Pi:\n",
        "            candidates.append(i)\n",
        "\n",
        "    # Control number of CHs\n",
        "    target_chs = p_opt * n_nodes\n",
        "    max_chs = int(max_chs_factor * target_chs)\n",
        "\n",
        "    # Too many CHs -> keep highest P_i\n",
        "    if len(candidates) > max_chs and max_chs > 0:\n",
        "        candidates = sorted(candidates, key=lambda idx: P_i[idx], reverse=True)\n",
        "        candidates = candidates[:max_chs]\n",
        "\n",
        "    # Too few CHs -> enforce at least min_chs highest P_i\n",
        "    if len(candidates) < min_chs:\n",
        "        top_indices = np.argsort(-P_i)[:min_chs]\n",
        "        candidates = list(top_indices)\n",
        "\n",
        "    return candidates\n",
        "\n",
        "print('L1: DEECP selection defined!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WvAN-z3l7XFH",
      "metadata": {
        "id": "WvAN-z3l7XFH"
      },
      "source": [
        "## 5. Proposed Method (RLHC) - Layer 2: EEKA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf6b48e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf6b48e7",
        "outputId": "e4aaaeb3-eacd-4a28-d216-57bd1a7441e7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def eeka_select_global(\n",
        "    candidates,\n",
        "    nodes_energy,\n",
        "    nodes_pos,\n",
        "    total_desired_k,\n",
        "    alpha=0.7,\n",
        "    beta=0.3\n",
        "):\n",
        "    \"\"\"\n",
        "    Simple global EEKA-like CH selection.\n",
        "\n",
        "    - For each node i:\n",
        "        w_e(i) = E_i / (mean(E_all) + eps)\n",
        "        c(i)   = 1 / (avg distance to all other nodes + eps)\n",
        "      Normalize both across all nodes, then:\n",
        "        U(i) = alpha * e_norm + beta * c_norm\n",
        "\n",
        "    - Candidate-first: first pick among 'candidates' by U,\n",
        "      if not enough, fill remaining CHs from non-candidates by U.\n",
        "    \"\"\"\n",
        "    # Make sure these are numpy arrays\n",
        "    nodes_energy = np.array(nodes_energy, dtype=float)\n",
        "    nodes_pos = np.array(nodes_pos, dtype=float)\n",
        "\n",
        "    n_nodes = len(nodes_energy)\n",
        "    if n_nodes == 0 or total_desired_k <= 0:\n",
        "        return []\n",
        "\n",
        "    # 1) Energy weight\n",
        "    eps = 1e-6\n",
        "    E_mean = float(nodes_energy.mean())\n",
        "    w_e = nodes_energy / (E_mean + eps)\n",
        "\n",
        "    # 2) Centrality (global)\n",
        "    centrality_vals = []\n",
        "    for i in range(n_nodes):\n",
        "        others = [j for j in range(n_nodes) if j != i]\n",
        "        if len(others) == 0:\n",
        "            centrality_vals.append(0.0)\n",
        "            continue\n",
        "        dists = [np.linalg.norm(nodes_pos[i] - nodes_pos[j]) for j in others]\n",
        "        avgd = float(np.mean(dists)) if len(dists) > 0 else 1e6\n",
        "        centrality_vals.append(1.0 / (avgd + eps))\n",
        "    centrality_vals = np.array(centrality_vals, dtype=float)\n",
        "\n",
        "    # 3) Normalize helper\n",
        "    def normalize(arr):\n",
        "        a_min = float(arr.min())\n",
        "        a_max = float(arr.max())\n",
        "        if a_max > a_min:\n",
        "            return (arr - a_min) / (a_max - a_min)\n",
        "        else:\n",
        "            return np.zeros_like(arr)\n",
        "\n",
        "    e_norm = normalize(w_e)\n",
        "    c_norm = normalize(centrality_vals)\n",
        "\n",
        "    # 4) Utility\n",
        "    utilities = alpha * e_norm + beta * c_norm\n",
        "    utility_dict = {i: float(utilities[i]) for i in range(n_nodes)}  # <-- use n_nodes\n",
        "\n",
        "    selected = []\n",
        "\n",
        "    # Candidate-first\n",
        "    if candidates is not None and len(candidates) > 0:\n",
        "        cand_sorted = sorted(candidates, key=lambda i: utility_dict[i], reverse=True)\n",
        "        selected.extend(cand_sorted[:total_desired_k])\n",
        "\n",
        "    # Fill with non-candidates if needed\n",
        "    if len(selected) < total_desired_k:\n",
        "        remaining_slots = total_desired_k - len(selected)\n",
        "        non_candidates = [i for i in range(n_nodes) if i not in selected]\n",
        "        noncand_sorted = sorted(non_candidates, key=lambda i: utility_dict[i], reverse=True)\n",
        "        selected.extend(noncand_sorted[:remaining_slots])\n",
        "\n",
        "    return selected[:total_desired_k]\n",
        "\n",
        "print('L2: EEKA filtering defined!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9XS1wgF07XFH",
      "metadata": {
        "id": "9XS1wgF07XFH"
      },
      "source": [
        "## 5. Proposed Method (RLHC) - Layer 3: K-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_8wMOYIC7XFI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8wMOYIC7XFI",
        "outputId": "f496a911-b440-496e-851c-5849d6d4bc57"
      },
      "outputs": [],
      "source": [
        "def kmeans_layer(nodes_pos, k, init_ch_indices=None, max_iter=20):\n",
        "    \"\"\"\n",
        "    Layer 3: K-means clustering using Layer-2 CHs as initial centroids.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    nodes_pos : array-like of shape (N, 2)\n",
        "        Positions (x, y) of all (alive) nodes.\n",
        "    k : int\n",
        "        Number of clusters (should match number of CHs).\n",
        "    init_ch_indices : list of int or None\n",
        "        Indices of CHs selected by Layer 2 (EEKA).\n",
        "        If provided, these are used as initial centroids.\n",
        "    max_iter : int\n",
        "        Maximum number of K-means iterations.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    clusters : list of lists\n",
        "        clusters[j] is the list of node indices assigned to cluster j.\n",
        "    centroids : list of (x, y)\n",
        "        Final centroid positions for each cluster.\n",
        "    \"\"\"\n",
        "    nodes_pos = np.array(nodes_pos, dtype=float)\n",
        "    n_nodes = len(nodes_pos)\n",
        "\n",
        "    if k <= 0 or n_nodes == 0:\n",
        "        return [], []\n",
        "\n",
        "    # Initialize centroids\n",
        "    if init_ch_indices is not None and len(init_ch_indices) >= k:\n",
        "        # Use positions of the first k CHs from Layer 2\n",
        "        centroids = [tuple(nodes_pos[i]) for i in init_ch_indices[:k]]\n",
        "    else:\n",
        "        # Fallback: random initialization\n",
        "        chosen = np.random.choice(range(n_nodes), k, replace=False)\n",
        "        centroids = [tuple(nodes_pos[i]) for i in chosen]\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        # Assignment step\n",
        "        clusters = [[] for _ in range(k)]\n",
        "        for i, p in enumerate(nodes_pos):\n",
        "            dists = [distance(p, c) for c in centroids]\n",
        "            idx = int(np.argmin(dists))\n",
        "            clusters[idx].append(i)\n",
        "\n",
        "        # Update step\n",
        "        new_centroids = []\n",
        "        for c in clusters:\n",
        "            if len(c) == 0:\n",
        "                # Empty cluster: reinitialize centroid randomly\n",
        "                new_centroids.append(tuple(nodes_pos[np.random.randint(0, n_nodes)]))\n",
        "            else:\n",
        "                xs = [nodes_pos[i][0] for i in c]\n",
        "                ys = [nodes_pos[i][1] for i in c]\n",
        "                new_centroids.append((float(np.mean(xs)), float(np.mean(ys))))\n",
        "\n",
        "        # Convergence check\n",
        "        if all(distance(centroids[i], new_centroids[i]) < 1e-3 for i in range(k)):\n",
        "            centroids = new_centroids\n",
        "            break\n",
        "\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return clusters, centroids\n",
        "\n",
        "print(\"L3: K-means clustering (Layer 3) defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eoSMZkH7XFI",
      "metadata": {
        "id": "7eoSMZkH7XFI"
      },
      "source": [
        "## 5. Proposed Method (RLHC) - Layer 4: RL Q-Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s4cu06qg7XFI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4cu06qg7XFI",
        "outputId": "9f020edf-9b98-4a7b-a9e9-efd441e73d40"
      },
      "outputs": [],
      "source": [
        "def choose_action(state, epsilon, Q):\n",
        "    if random.random() < epsilon:\n",
        "        return random.choice(ACTIONS)\n",
        "    else:\n",
        "        qs = Q[state]\n",
        "        maxv = np.max(qs)\n",
        "        maxacts = [a for a,v in enumerate(qs) if abs(v-maxv) < 1e-9]\n",
        "        return random.choice(maxacts)\n",
        "\n",
        "def compute_reward(avg_e_before, avg_e_after, pdr_after, action_cost, target_pdr=0.95):\n",
        "    \"\"\"\n",
        "    Reward function for RL:\n",
        "    - Encourages slower energy depletion (higher avg_e_after).\n",
        "    - Encourages PDR >= target_pdr.\n",
        "    - Penalizes large action_cost.\n",
        "    \"\"\"\n",
        "    delta_E   = avg_e_after - avg_e_before     # usually small negative\n",
        "    delta_PDR = pdr_after - target_pdr         # positive if PDR > target\n",
        "\n",
        "    R_alpha = 50.0   # weight for energy\n",
        "    R_beta  = 20.0   # weight for PDR\n",
        "    R_gamma = 1.0    # weight for action cost\n",
        "\n",
        "    reward = R_alpha * delta_E + R_beta * delta_PDR - R_gamma * action_cost\n",
        "    return reward\n",
        "\n",
        "\n",
        "def update_q(Q, state, action, reward, avg_e_after, cluster_sizes, pdr_after, epsilon, LOAD_BINS, PDR_BINS):\n",
        "    next_state = state_from_metrics(avg_e_after, cluster_sizes, pdr_after, LOAD_BINS, PDR_BINS)\n",
        "    s = state\n",
        "    a = action\n",
        "    oldQ = Q[s][a]\n",
        "    Q[s][a] = oldQ + ALPHA * (reward + GAMMA * np.max(Q[next_state]) - oldQ)\n",
        "    epsilon = max(EPS_MIN, epsilon * EPS_DECAY)\n",
        "    return Q, epsilon\n",
        "\n",
        "print('L4: Q-Learning module defined!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8793d7bb",
      "metadata": {
        "id": "8793d7bb"
      },
      "source": [
        "## 5. Proposed Method (RLHC) - Layer 5: Communication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5941e5c5",
      "metadata": {
        "id": "5941e5c5"
      },
      "outputs": [],
      "source": [
        "def link_cost_ch_to_ch(i, j, bits, chs, ch_positions, nodes_energy,\n",
        "                       alpha_energy=0.1, relay_min_energy=0.07):\n",
        "    \"\"\"\n",
        "    Cost for link CH_i -> CH_j (indices in chs list).\n",
        "\n",
        "    - If CH_j energy < relay_min_energy: we avoid using it as relay.\n",
        "    - Otherwise: tx energy + penalty based on relay's energy.\n",
        "    \"\"\"\n",
        "    relay_node_id = chs[j]\n",
        "    relay_energy = nodes_energy[relay_node_id] + 1e-9  # avoid div-by-zero\n",
        "\n",
        "    # HARD FILTER: do not use almost-dead CHs as relays\n",
        "    if relay_energy < relay_min_energy:\n",
        "        return 1e12  # huge cost: Dijkstra will avoid this edge\n",
        "\n",
        "    from_pos = ch_positions[i]\n",
        "    to_pos   = ch_positions[j]\n",
        "    d = distance(from_pos, to_pos)\n",
        "    E_tx = energy_tx(bits, d)\n",
        "\n",
        "    # SOFT penalty: prefer high-energy relays\n",
        "    penalty = alpha_energy * (1.0 / relay_energy)\n",
        "\n",
        "    return E_tx + penalty\n",
        "\n",
        "\n",
        "def link_cost_ch_to_bs(i, bits, ch_positions, bs_pos):\n",
        "    \"\"\"\n",
        "    Cost for link CH_i -> BS.\n",
        "    \"\"\"\n",
        "    d = distance(ch_positions[i], bs_pos)\n",
        "    return energy_tx(bits, d)\n",
        "\n",
        "\n",
        "def dijkstra_ch_to_bs(start_idx, neighbors, chs, ch_positions,\n",
        "                      nodes_energy, bs_pos, bits,\n",
        "                      alpha_energy=0.1, relay_min_energy=0.07):\n",
        "    \"\"\"\n",
        "    Compute min-cost path from CH[start_idx] to BS.\n",
        "    Returns:\n",
        "        path_idx: list of indices (0..len(chs)-1) plus -1 representing BS\n",
        "        best_cost: total cost along this path\n",
        "    \"\"\"\n",
        "    N = len(chs)\n",
        "    INF = 1e18\n",
        "    dist_arr = [INF] * N\n",
        "    prev = [None] * N\n",
        "\n",
        "    dist_arr[start_idx] = 0.0\n",
        "    pq = [(0.0, start_idx)]\n",
        "\n",
        "    while pq:\n",
        "        cur_d, u = heapq.heappop(pq)\n",
        "        if cur_d > dist_arr[u]:\n",
        "            continue\n",
        "\n",
        "        for v in neighbors[u]:\n",
        "            c_uv = link_cost_ch_to_ch(i=u, j=v, bits=bits, chs=chs, ch_positions=ch_positions, nodes_energy=nodes_energy, alpha_energy=alpha_energy, relay_min_energy=relay_min_energy)\n",
        "            nd = cur_d + c_uv\n",
        "            if nd < dist_arr[v]:\n",
        "                dist_arr[v] = nd\n",
        "                prev[v] = u\n",
        "                heapq.heappush(pq, (nd, v))\n",
        "\n",
        "    # Best option: either direct start->BS or via some CH k -> BS\n",
        "    best_cost = link_cost_ch_to_bs(start_idx, bits, ch_positions, bs_pos)\n",
        "    best_last = None  # None => direct to BS\n",
        "\n",
        "    for k in range(N):\n",
        "        if dist_arr[k] >= INF:\n",
        "            continue\n",
        "        cost_k_bs = link_cost_ch_to_bs(k, bits, ch_positions, bs_pos)\n",
        "        total_cost = dist_arr[k] + cost_k_bs\n",
        "        if total_cost < best_cost:\n",
        "            best_cost = total_cost\n",
        "            best_last = k\n",
        "\n",
        "    # Reconstruct path\n",
        "    if best_last is None:\n",
        "        # Best is direct: [start_idx, BS]\n",
        "        return [start_idx, -1], best_cost\n",
        "\n",
        "    # If best_last has no predecessor, path is [start_idx (=best_last), BS]\n",
        "    if prev[best_last] is None and best_last == start_idx:\n",
        "        return [start_idx, -1], best_cost\n",
        "\n",
        "    # General case: follow predecessors back to start\n",
        "    path_nodes = [best_last]\n",
        "    cur = best_last\n",
        "    while prev[cur] is not None:\n",
        "        cur = prev[cur]\n",
        "        if cur not in path_nodes:\n",
        "            path_nodes.append(cur)\n",
        "        else:\n",
        "            # safety break in case of any weird cycle (should not happen)\n",
        "            break\n",
        "\n",
        "    # Ensure start_idx is present\n",
        "    if start_idx not in path_nodes:\n",
        "        path_nodes.append(start_idx)\n",
        "\n",
        "    path_nodes.reverse()  # from start_idx ... best_last\n",
        "    path_idx = path_nodes + [-1]  # append BS as -1\n",
        "\n",
        "    return path_idx, best_cost\n",
        "\n",
        "\n",
        "def multi_hop_comm_layer5(clusters, chs, nodes_energy, nodes_pos, base_station, tx_power_factor, pkt_size, max_hop_dist, alpha_energy=0.1,\n",
        "    relay_min_energy=0.7,\n",
        "    max_hops_per_route=2,\n",
        "    forward_limit=3\n",
        "):\n",
        "    \"\"\"\n",
        "    Layer 5 communication:\n",
        "      1) members -> CH (single-hop)\n",
        "      2) CHs -> BS (multi-hop, optimized routes)\n",
        "    Returns:\n",
        "      nodes_energy (updated),\n",
        "      successful_packets,\n",
        "      total_packets,\n",
        "      links_this_round  # NEW: list of (src, dst) hops for this round\n",
        "    \"\"\"\n",
        "    successful_packets = 0\n",
        "    total_packets = 0\n",
        "\n",
        "    # NEW: collect all hops of this round\n",
        "    links_this_round = []\n",
        "\n",
        "    # -----------------------------\n",
        "    # Build CH graph & routes\n",
        "    # -----------------------------\n",
        "    ch_positions = [nodes_pos[ch] for ch in chs]\n",
        "    N_ch = len(chs)\n",
        "\n",
        "    neighbors = [[] for _ in range(N_ch)]\n",
        "    for i in range(N_ch):\n",
        "        for j in range(N_ch):\n",
        "            if i == j:\n",
        "                continue\n",
        "            dij = distance(ch_positions[i], ch_positions[j])\n",
        "            if dij <= max_hop_dist:\n",
        "                neighbors[i].append(j)\n",
        "\n",
        "    ch_routes = {}\n",
        "    ch_index = {ch_id: idx for idx, ch_id in enumerate(chs)}\n",
        "\n",
        "    for idx, ch_node_id in enumerate(chs):\n",
        "        if nodes_energy[ch_node_id] <= 0:\n",
        "            ch_routes[ch_node_id] = [ch_node_id, \"BS\"]\n",
        "            continue\n",
        "\n",
        "        path_idx, _ = dijkstra_ch_to_bs(\n",
        "            start_idx=idx,\n",
        "            neighbors=neighbors,\n",
        "            chs=chs,\n",
        "            ch_positions=ch_positions,\n",
        "            nodes_energy=nodes_energy,\n",
        "            bs_pos=base_station,\n",
        "            bits=pkt_size,\n",
        "            alpha_energy=alpha_energy,\n",
        "            relay_min_energy=relay_min_energy\n",
        "        )\n",
        "\n",
        "        node_path = []\n",
        "        for p in path_idx:\n",
        "            if p == -1:\n",
        "                node_path.append(\"BS\")\n",
        "            else:\n",
        "                node_path.append(chs[p])\n",
        "\n",
        "        hops = len(node_path) - 1\n",
        "        if hops > max_hops_per_route:\n",
        "            node_path = [ch_node_id, \"BS\"]\n",
        "\n",
        "        ch_routes[ch_node_id] = node_path\n",
        "\n",
        "    # -----------------------------\n",
        "    # 1) Intra-cluster: members -> CH\n",
        "    # -----------------------------\n",
        "    for cidx, cluster_nodes in enumerate(clusters):\n",
        "        if not cluster_nodes:\n",
        "            continue\n",
        "        ch_node = chs[cidx]\n",
        "        if nodes_energy[ch_node] <= 0:\n",
        "            continue\n",
        "\n",
        "        ch_pos = nodes_pos[ch_node]\n",
        "        for node in cluster_nodes:\n",
        "            if node == ch_node:\n",
        "                continue\n",
        "            if nodes_energy[node] <= 0:\n",
        "                continue\n",
        "\n",
        "            d = distance(nodes_pos[node], ch_pos)\n",
        "            E_tx = energy_tx(pkt_size, d) * tx_power_factor\n",
        "            E_rx = energy_rx(pkt_size)\n",
        "\n",
        "            nodes_energy[node]    -= E_tx\n",
        "            nodes_energy[ch_node] -= E_rx\n",
        "\n",
        "            # log member -> CH hop\n",
        "            links_this_round.append((node, ch_node))\n",
        "\n",
        "            total_packets += 1\n",
        "            successful_packets += 1  # assuming reliable intra-cluster\n",
        "\n",
        "    # -----------------------------\n",
        "    # 2) Inter-cluster: CHs -> BS (multi-hop)\n",
        "    # -----------------------------\n",
        "    forward_count = {ch: 0 for ch in chs}\n",
        "\n",
        "    for ch_node in chs:\n",
        "        if nodes_energy[ch_node] <= 0:\n",
        "            continue\n",
        "\n",
        "        route = ch_routes[ch_node]  # e.g. [ch, relay1, ..., \"BS\"]\n",
        "        if len(route) < 2:\n",
        "            continue\n",
        "\n",
        "        first_hop_counted = False\n",
        "        sender = route[0]\n",
        "\n",
        "        for hop_idx in range(len(route) - 1):\n",
        "            receiver = route[hop_idx + 1]\n",
        "\n",
        "            if sender == \"BS\":\n",
        "                break\n",
        "            if nodes_energy[sender] <= 0:\n",
        "                break  # sender dead, packet lost\n",
        "\n",
        "            if receiver == \"BS\":\n",
        "                # last hop to BS\n",
        "                d = distance(nodes_pos[sender], base_station)\n",
        "                E_tx = energy_tx(pkt_size, d) * tx_power_factor\n",
        "                nodes_energy[sender] -= E_tx\n",
        "\n",
        "                # log CH -> BS hop as (sender, -1) so we can handle BS specially\n",
        "                links_this_round.append((sender, -1))\n",
        "\n",
        "                if not first_hop_counted:\n",
        "                    total_packets += 1\n",
        "                    successful_packets += 1\n",
        "                    first_hop_counted = True\n",
        "\n",
        "                break\n",
        "\n",
        "            else:\n",
        "                # relay CH\n",
        "                if nodes_energy[receiver] <= 0:\n",
        "                    break  # relay dead, packet lost\n",
        "\n",
        "                if forward_count[receiver] >= forward_limit:\n",
        "                    break  # relay overloaded\n",
        "\n",
        "                d = distance(nodes_pos[sender], nodes_pos[receiver])\n",
        "                E_tx = energy_tx(pkt_size, d) * tx_power_factor\n",
        "                E_rx = energy_rx(pkt_size)\n",
        "\n",
        "                nodes_energy[sender]   -= E_tx\n",
        "                nodes_energy[receiver] -= E_rx\n",
        "\n",
        "                forward_count[receiver] += 1\n",
        "\n",
        "                # log CH -> relay hop\n",
        "                links_this_round.append((sender, receiver))\n",
        "\n",
        "                if not first_hop_counted:\n",
        "                    total_packets += 1\n",
        "                    successful_packets += 1\n",
        "                    first_hop_counted = True\n",
        "\n",
        "                sender = receiver  # move along the path\n",
        "\n",
        "    return nodes_energy, successful_packets, total_packets, links_this_round\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Af1hHA6w7XFJ",
      "metadata": {
        "id": "Af1hHA6w7XFJ"
      },
      "source": [
        "## 5. Proposed Method (RLHC) - Main Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ay-yH02j7XFJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay-yH02j7XFJ",
        "outputId": "b8173dd9-a5b2-459a-d279-a1386abbd6bf"
      },
      "outputs": [],
      "source": [
        "def run_proposed():\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    avg_energy_history = []\n",
        "    pdr_history = []\n",
        "    alive_nodes_history = []\n",
        "    alive_nodes_per_round = []\n",
        "    num_ch_history = []\n",
        "    reward_history = []\n",
        "    epsilon_history = []\n",
        "    throughput_history = []\n",
        "    pdr_percent_history = []\n",
        "    total_energy_history = []\n",
        "    first_dead_round = None\n",
        "    half_dead_round = None\n",
        "    last_dead_round = None\n",
        "\n",
        "    # RL state-discretization bins and Q-table\n",
        "    LOAD_BINS, PDR_BINS = build_bins()\n",
        "    Q = defaultdict(lambda: np.zeros(len(ACTIONS)))\n",
        "    epsilon = EPSILON   # e.g., 1.0\n",
        "\n",
        "    # Network initialization\n",
        "    nodes_pos = [(random.uniform(0, AREA_SIZE), random.uniform(0, AREA_SIZE)) for _ in range(N_NODES)]\n",
        "    sector_ids = assign_static_sectors(nodes_pos, AREA_SIZE, SECTOR_ROWS, SECTOR_COLS)\n",
        "\n",
        "\n",
        "    # Heterogeneous initial energies ONCE (not every round)\n",
        "    nodes_energy, is_advanced = initialize_heterogeneous_energies()\n",
        "    nodes_energy = np.array(nodes_energy, dtype=float)\n",
        "\n",
        "    tx_power_factor = 1.0\n",
        "    TARGET_PDR = 0.9   # desired PDR target for reward shaping\n",
        "\n",
        "    for rnd in range(1, ROUNDS + 1):\n",
        "        base_station = get_bs_position(rnd)\n",
        "        # -------------------------\n",
        "        # Layer 1: DEEC/DEECP → candidates\n",
        "        # -------------------------\n",
        "        candidates = deec_select(nodes_energy, p_opt=P_OPT)\n",
        "\n",
        "        # -------------------------\n",
        "        # Layer 2: EEKA based → preliminary CHs\n",
        "        # -------------------------\n",
        "        final_CHs = eeka_select_global(\n",
        "            candidates=candidates,\n",
        "            nodes_energy=nodes_energy,\n",
        "            nodes_pos=nodes_pos,\n",
        "            total_desired_k=NUM_CLUSTERS,\n",
        "            alpha=0.7,\n",
        "            beta=0.3\n",
        "        )\n",
        "\n",
        "        # -------------------------\n",
        "        # Layer 3: K-means clustering around Layer-2 CHs\n",
        "        # -------------------------\n",
        "        clusters, centroids = kmeans_layer(\n",
        "            nodes_pos=nodes_pos,\n",
        "            k=len(final_CHs),           # usually == NUM_CLUSTERS\n",
        "            init_ch_indices=final_CHs,  # Layer-2 CH indices as init points\n",
        "            max_iter=20\n",
        "        )\n",
        "\n",
        "        # Final CH refinement per cluster\n",
        "        final_chs = []\n",
        "        for cidx, cluster_nodes in enumerate(clusters):\n",
        "            if len(cluster_nodes) == 0:\n",
        "                # Empty cluster: choose the global highest-energy node as CH (fallback)\n",
        "                final_chs.append(int(np.argmax(nodes_energy)))\n",
        "                continue\n",
        "            centroid = centroids[cidx]\n",
        "\n",
        "            # CHs that EEKA (Layer 2) selected within this cluster:\n",
        "            ee_ka_in_cluster = [ch for ch in final_CHs if ch in cluster_nodes]\n",
        "            if ee_ka_in_cluster:\n",
        "                nearest_ch = min(ee_ka_in_cluster, key=lambda ch: distance(nodes_pos[ch], centroid))\n",
        "                final_chs.append(nearest_ch)\n",
        "            else:\n",
        "                # If no EEKA CH in this cluster, pick highest-energy member\n",
        "                highest_energy_node = max(cluster_nodes, key=lambda n: nodes_energy[n])\n",
        "                final_chs.append(highest_energy_node)\n",
        "\n",
        "        chs = final_chs\n",
        "\n",
        "        # -------------------------\n",
        "        # Layer 4: Q-learning based control\n",
        "        # -------------------------\n",
        "        avg_e_before = np.mean(nodes_energy)\n",
        "\n",
        "        # Define RL state from current metrics (before action)\n",
        "        cluster_sizes = [len(c) for c in clusters] if clusters else [0]\n",
        "        state = state_from_metrics(\n",
        "            avg_e_before,\n",
        "            cluster_sizes,\n",
        "            TARGET_PDR,   # using target PDR in state representation as well\n",
        "            LOAD_BINS,\n",
        "            PDR_BINS\n",
        "        )\n",
        "\n",
        "        # Choose action via epsilon-greedy\n",
        "        action = choose_action(state, epsilon, Q)\n",
        "\n",
        "        # Check if reassignment is worth doing (load imbalance condition)\n",
        "        max_cluster = max([len(c) for c in clusters]) if clusters else 0\n",
        "        mean_cluster = np.mean([len(c) for c in clusters]) if clusters else 0\n",
        "        allow_reassign = (mean_cluster > 0 and max_cluster > 1.5 * mean_cluster)\n",
        "        if action == A_REASSIGN_FEW and not allow_reassign:\n",
        "            action = A_NOOP\n",
        "\n",
        "        # Apply action\n",
        "        action_cost = 0.0\n",
        "        if action == A_NOOP:\n",
        "            pass\n",
        "\n",
        "        elif action == A_REASSIGN_FEW:\n",
        "            largest_idx = int(np.argmax([len(c) for c in clusters]))\n",
        "            if len(clusters[largest_idx]) > 0:\n",
        "                m = max(1, int(0.05 * len(clusters[largest_idx])))\n",
        "                members = clusters[largest_idx].copy()\n",
        "                # Sort members: farthest from CH first\n",
        "                members.sort(\n",
        "                    key=lambda n: distance(nodes_pos[n], nodes_pos[chs[largest_idx]]),\n",
        "                    reverse=True\n",
        "                )\n",
        "                moved = 0\n",
        "                for node in members:\n",
        "                    if moved >= m:\n",
        "                        break\n",
        "                    # Candidate clusters: those less loaded than mean\n",
        "                    candidates_ch = [\n",
        "                        i for i in range(len(clusters))\n",
        "                        if len(clusters[i]) < mean_cluster\n",
        "                    ]\n",
        "                    if not candidates_ch:\n",
        "                        break\n",
        "                    best = min(\n",
        "                        candidates_ch,\n",
        "                        key=lambda cidx: distance(nodes_pos[node], nodes_pos[chs[cidx]])\n",
        "                    )\n",
        "                    clusters[largest_idx].remove(node)\n",
        "                    clusters[best].append(node)\n",
        "                    moved += 1\n",
        "                    action_cost += 0.5   # slightly higher cost for reassignment\n",
        "\n",
        "        elif action == A_SWITCH_CH:\n",
        "            largest_idx = int(np.argmax([len(c) for c in clusters]))\n",
        "            if len(clusters[largest_idx]) > 1:\n",
        "                candidate = max(\n",
        "                    [n for n in clusters[largest_idx] if n != chs[largest_idx]],\n",
        "                    key=lambda x: nodes_energy[x]\n",
        "                )\n",
        "                old_ch = chs[largest_idx]\n",
        "                chs[largest_idx] = candidate\n",
        "                action_cost += 0.3\n",
        "\n",
        "        elif action == A_REDUCE_TX:\n",
        "            tx_power_factor = max(0.5, tx_power_factor * 0.9)\n",
        "            action_cost += 0.05\n",
        "\n",
        "        elif action == A_INCREASE_TX:\n",
        "            tx_power_factor = min(1.5, tx_power_factor * 1.1)\n",
        "            action_cost += 0.05\n",
        "\n",
        "        # -------------------------\n",
        "        # Radio communication & metrics\n",
        "        # -------------------------\n",
        "        successful_packets = 0\n",
        "        total_packets = 0\n",
        "\n",
        "        # -------------------------\n",
        "        # Layer 5: Multi-hop communication & metrics\n",
        "        # -------------------------\n",
        "        METHOD_NAME_RLHC = \"RLHC_PROPOSED\"\n",
        "        links_this_round = []\n",
        "        \n",
        "        if ENABLE_MULTI_HOP:\n",
        "            MAX_HOP_DIST = AREA_SIZE * 0.4  # tune as needed\n",
        "            nodes_energy, successful_packets, total_packets, links_this_round = multi_hop_comm_layer5(\n",
        "                clusters=clusters,\n",
        "                chs=chs,\n",
        "                nodes_energy=nodes_energy,\n",
        "                nodes_pos=nodes_pos,\n",
        "                base_station=base_station,\n",
        "                tx_power_factor=tx_power_factor,\n",
        "                pkt_size=PACKET_SIZE_BITS,\n",
        "                max_hop_dist=MAX_HOP_DIST,\n",
        "                alpha_energy=0.2,\n",
        "                relay_min_energy=0.2,    # try 20% of E_INIT\n",
        "                max_hops_per_route=3,     # try 2, 3, 4\n",
        "                forward_limit=3            # try 2, 4\n",
        "            )\n",
        "        else:\n",
        "            nodes_energy, successful_packets, total_packets = radio_comm( clusters, chs, nodes_energy, nodes_pos, base_station, tx_power_factor, successful_packets, total_packets)\n",
        "            \n",
        "            # For logging/visualization, define links_this_round as direct CH -> BS hops\n",
        "            for cidx, ch in enumerate(chs):\n",
        "                if len(clusters[cidx]) == 0:\n",
        "                    continue\n",
        "                # Log one logical link CH -> BS (dst = -1 convention)\n",
        "                links_this_round.append((ch, -1))\n",
        "            \n",
        "        # must match the string used in sector_life_table[\"Method\"]\n",
        "        for (src, dst) in links_this_round:\n",
        "            log_link(METHOD_NAME_RLHC, rnd, src, dst)\n",
        "            \n",
        "        log_chs_and_clusters(METHOD_NAME_RLHC, rnd, chs, clusters)\n",
        "\n",
        "        # -------------------------\n",
        "        # Metrics & logging\n",
        "        # -------------------------\n",
        "        nodes_energy = np.maximum(nodes_energy, 0.0)\n",
        "\n",
        "        avg_e_after, pdr_after, alive_after, cluster_sizes = measure_metrics(\n",
        "            nodes_energy,\n",
        "            clusters,\n",
        "            chs,\n",
        "            successful_packets,\n",
        "            total_packets\n",
        "        )\n",
        "\n",
        "        # -------------------------\n",
        "        # Reward & Q update\n",
        "        # -------------------------\n",
        "        reward = compute_reward(\n",
        "            avg_e_before,\n",
        "            avg_e_after,\n",
        "            pdr_after,\n",
        "            action_cost,\n",
        "            target_pdr=TARGET_PDR\n",
        "        )\n",
        "\n",
        "        # Stronger penalty if some new deaths occurred\n",
        "        if any(nodes_energy <= 0):\n",
        "            reward -= 10.0\n",
        "\n",
        "        Q, epsilon = update_q(\n",
        "            Q,\n",
        "            state,\n",
        "            action,\n",
        "            reward,\n",
        "            avg_e_after,\n",
        "            cluster_sizes,\n",
        "            pdr_after,\n",
        "            epsilon,\n",
        "            LOAD_BINS,\n",
        "            PDR_BINS\n",
        "        )\n",
        "\n",
        "        # -------------------------\n",
        "        # Lifetime tracking\n",
        "        # -------------------------\n",
        "        if first_dead_round is None and alive_after < N_NODES:\n",
        "            first_dead_round = rnd\n",
        "        if half_dead_round is None and alive_after <= N_HALF:\n",
        "            half_dead_round = rnd\n",
        "        if alive_after == 0 and last_dead_round is None:\n",
        "            last_dead_round = rnd\n",
        "\n",
        "        # -------------------------\n",
        "        # Logging\n",
        "        # -------------------------\n",
        "        alive_nodes = nodes_energy > 0\n",
        "        alive_nodes_indices = np.where(alive_nodes)[0].tolist()\n",
        "        alive_nodes_per_round.append(alive_nodes_indices)\n",
        "        avg_energy_history.append(avg_e_after)\n",
        "        total_energy_history.append(float(np.sum(nodes_energy)))\n",
        "        pdr_history.append(pdr_after)\n",
        "        alive_nodes_history.append(alive_after)\n",
        "        num_ch_history.append(len(chs))\n",
        "        reward_history.append(reward)\n",
        "        epsilon_history.append(epsilon)\n",
        "        throughput_history.append(successful_packets)\n",
        "        pdr_percent_history.append(\n",
        "            100.0 * successful_packets / (total_packets + 1e-12)\n",
        "        )\n",
        "\n",
        "        if alive_after == 0:\n",
        "            print(f\"[RLHC_PROPOSED] All nodes died at round {rnd}\")\n",
        "            break\n",
        "\n",
        "    return (\n",
        "        avg_energy_history,\n",
        "        pdr_history,\n",
        "        alive_nodes_history,\n",
        "        alive_nodes_per_round,\n",
        "        num_ch_history,\n",
        "        reward_history,\n",
        "        epsilon_history,\n",
        "        throughput_history,\n",
        "        pdr_percent_history,\n",
        "        first_dead_round,\n",
        "        half_dead_round,\n",
        "        last_dead_round,\n",
        "        sector_ids,\n",
        "        nodes_pos,\n",
        "        total_energy_history\n",
        "    )\n",
        "\n",
        "print('Proposed RLHC algorithm defined (updated with tuned reward & fixes)!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gtvqeFC37XFK",
      "metadata": {
        "id": "gtvqeFC37XFK"
      },
      "source": [
        "## 6. Baseline Algorithm: LEACH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CGXgFvin7XFK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGXgFvin7XFK",
        "outputId": "0322d80d-b64c-43a9-f67a-b93e7a0b8eec"
      },
      "outputs": [],
      "source": [
        "def select_CHs_leach(alive_nodes, round_num, last_ch_round, p_opt=P_OPT):\n",
        "    \"\"\"\n",
        "    Standard LEACH CH selection:\n",
        "    - Constant probability p_opt for all nodes\n",
        "    - Epoch = 1 / p_opt\n",
        "    - G-set based on last CH round\n",
        "    \"\"\"\n",
        "\n",
        "    is_CH = np.zeros(N_NODES, dtype=bool)\n",
        "\n",
        "    # Epoch length\n",
        "    if p_opt <= 0:\n",
        "        return is_CH\n",
        "    epoch = int(1.0 / p_opt)\n",
        "    epoch = max(epoch, 1)  # avoid zero\n",
        "\n",
        "    for i in range(N_NODES):\n",
        "        if not alive_nodes[i]:\n",
        "            continue\n",
        "\n",
        "        # Check if node i is in G (eligible this round)\n",
        "        rounds_since_last_CH = round_num - last_ch_round[i]\n",
        "        in_G = rounds_since_last_CH >= epoch\n",
        "\n",
        "        if not in_G:\n",
        "            continue\n",
        "\n",
        "        # LEACH threshold\n",
        "        r_mod = round_num % epoch\n",
        "        denominator = 1.0 - p_opt * r_mod\n",
        "        if denominator <= 0:\n",
        "            threshold = 0.0\n",
        "        else:\n",
        "            threshold = p_opt / denominator\n",
        "\n",
        "        if np.random.rand() < threshold:\n",
        "            is_CH[i] = True\n",
        "            last_ch_round[i] = round_num\n",
        "\n",
        "    # Safety: if no CH selected, pick one alive node randomly\n",
        "    if not is_CH.any():\n",
        "        alive_idx = np.where(alive_nodes)[0]\n",
        "        if len(alive_idx) > 0:\n",
        "            chosen = np.random.choice(alive_idx)\n",
        "            is_CH[chosen] = True\n",
        "            last_ch_round[chosen] = round_num\n",
        "\n",
        "    return is_CH\n",
        "\n",
        "\n",
        "def run_leach():\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    avg_energy_history = []\n",
        "    pdr_history = []\n",
        "    alive_nodes_history = []\n",
        "    alive_nodes_per_round = []\n",
        "    num_ch_history = []\n",
        "    reward_history = []\n",
        "    epsilon_history = []\n",
        "    throughput_history = []\n",
        "    pdr_percent_history = []\n",
        "    total_energy_history = []\n",
        "    first_dead_round = None\n",
        "    half_dead_round = None\n",
        "    last_dead_round = None\n",
        "\n",
        "    # Node positions\n",
        "    nodes_pos = [(random.uniform(0, AREA_SIZE), random.uniform(0, AREA_SIZE))for _ in range(N_NODES)]\n",
        "    sector_ids = assign_static_sectors(nodes_pos, AREA_SIZE, SECTOR_ROWS, SECTOR_COLS)\n",
        "\n",
        "    nodes_energy = np.array([INIT_ENERGY] * N_NODES, dtype=float)\n",
        "\n",
        "    # Track last CH round per node (for G-set)\n",
        "    last_ch_round = np.full(N_NODES, -1_000_000, dtype=int)\n",
        "\n",
        "    for rnd in range(1, ROUNDS + 1):\n",
        "        base_station = get_bs_position(rnd)\n",
        "        alive_nodes = nodes_energy > 0\n",
        "\n",
        "        # LEACH CH selection (literature-style)\n",
        "        is_CH = select_CHs_leach(\n",
        "            alive_nodes=alive_nodes,\n",
        "            round_num=rnd,\n",
        "            last_ch_round=last_ch_round,\n",
        "            p_opt=P_OPT\n",
        "        )\n",
        "        chs = np.where(is_CH)[0].tolist()\n",
        "\n",
        "        if len(chs) == 0:\n",
        "            # Extra safety (should be rare due to fallback)\n",
        "            alive_idx = np.where(alive_nodes)[0]\n",
        "            if len(alive_idx) > 0:\n",
        "                chosen = random.choice(alive_idx.tolist())\n",
        "                chs = [chosen]\n",
        "\n",
        "        # Clustering: each alive node joins nearest CH\n",
        "        clusters = [[] for _ in range(len(chs))]\n",
        "        for i in range(N_NODES):\n",
        "            if nodes_energy[i] <= 0:\n",
        "                continue\n",
        "            nearest_ch = min(\n",
        "                range(len(chs)),\n",
        "                key=lambda j: distance(nodes_pos[i], nodes_pos[chs[j]])\n",
        "            )\n",
        "            clusters[nearest_ch].append(i)\n",
        "\n",
        "        # Communication (end-to-end PDR)\n",
        "        nodes_energy, successful_packets, total_packets = radio_comm(\n",
        "            clusters, chs, nodes_energy, nodes_pos, base_station,\n",
        "            tx_power_factor=1.0,\n",
        "            successful_packets=0,\n",
        "            total_packets=0\n",
        "        )\n",
        "\n",
        "        nodes_energy = np.maximum(nodes_energy, 0.0)\n",
        "\n",
        "        avg_e_after, pdr_after, alive_after, cluster_sizes = measure_metrics(\n",
        "            nodes_energy, clusters, chs, successful_packets, total_packets\n",
        "        )\n",
        "\n",
        "        if first_dead_round is None and alive_after < N_NODES:\n",
        "            first_dead_round = rnd\n",
        "        if half_dead_round is None and alive_after <= N_HALF:\n",
        "            half_dead_round = rnd\n",
        "        if alive_after == 0 and last_dead_round is None:\n",
        "            last_dead_round = rnd\n",
        "\n",
        "        alive_nodes_indices = np.where(alive_nodes)[0].tolist()\n",
        "        alive_nodes_per_round.append(alive_nodes_indices)\n",
        "        avg_energy_history.append(avg_e_after)\n",
        "        total_energy_history.append(float(np.sum(nodes_energy)))\n",
        "        pdr_history.append(pdr_after)\n",
        "        alive_nodes_history.append(alive_after)\n",
        "        num_ch_history.append(len(chs))\n",
        "        reward_history.append(0.0)\n",
        "        epsilon_history.append(0.0)\n",
        "        throughput_history.append(successful_packets)\n",
        "        pdr_percent_history.append(\n",
        "            100.0 * successful_packets / (total_packets + 1e-12)\n",
        "        )\n",
        "\n",
        "        if alive_after == 0:\n",
        "            print(f\"[LEACH_BASELINE] All nodes died at round {rnd}\")\n",
        "            break\n",
        "\n",
        "    return (\n",
        "        avg_energy_history, pdr_history, alive_nodes_history, alive_nodes_per_round, num_ch_history,\n",
        "        reward_history, epsilon_history, throughput_history, pdr_percent_history,\n",
        "        first_dead_round, half_dead_round, last_dead_round, sector_ids, nodes_pos, total_energy_history\n",
        "    )\n",
        "\n",
        "print('LEACH baseline algorithm (with standard threshold) defined!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q-AyrQer7XFL",
      "metadata": {
        "id": "q-AyrQer7XFL"
      },
      "source": [
        "## 6. Baseline Algorithm: DEEC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-xAth5IO7XFL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xAth5IO7XFL",
        "outputId": "f7062557-8ddd-411e-b5f6-625ecf4971a0"
      },
      "outputs": [],
      "source": [
        "def select_CHs_deec(nodes_energy,\n",
        "                    alive_nodes,\n",
        "                    round_num,\n",
        "                    last_ch_round,\n",
        "                    p_opt=P_OPT,\n",
        "                    m_fraction_adv=M_FRACTION_ADV,\n",
        "                    a_adv=A_ADV_ENERGY):\n",
        "    \"\"\"\n",
        "    DEEC CH selection with:\n",
        "    - Heterogeneous energy (normal & advanced nodes)\n",
        "    - Explicit G-set using per-node last CH round.\n",
        "\n",
        "    nodes_energy   : array of current residual energies\n",
        "    alive_nodes    : boolean array, True if node is alive\n",
        "    round_num      : current round index (1-based)\n",
        "    last_ch_round  : array storing the last round when node i was CH\n",
        "    \"\"\"\n",
        "\n",
        "    is_CH = np.zeros(N_NODES, dtype=bool)\n",
        "\n",
        "    # Current average residual energy of alive nodes\n",
        "    total_energy_alive = np.sum(nodes_energy[alive_nodes])\n",
        "    num_alive = np.sum(alive_nodes)\n",
        "    if num_alive <= 0 or total_energy_alive <= 0:\n",
        "        return is_CH  # no alive nodes, no CHs\n",
        "\n",
        "    E_avg = total_energy_alive / float(num_alive)\n",
        "\n",
        "    # Average energy factor due to heterogeneity\n",
        "    # E_bar0 = E0 * (1 + a * m)\n",
        "    hetero_factor = 1.0 + a_adv * m_fraction_adv  # used in DEEC literature\n",
        "\n",
        "    for i in range(N_NODES):\n",
        "        if not alive_nodes[i]:\n",
        "            continue\n",
        "        if nodes_energy[i] <= 0:\n",
        "            continue\n",
        "\n",
        "        # Node-specific probability Pi\n",
        "        Pi = p_opt * (nodes_energy[i] / (E_avg * hetero_factor))\n",
        "\n",
        "        # Clamp to avoid extreme values\n",
        "        Pi = max(1e-6, min(Pi, 0.9))\n",
        "\n",
        "        # Epoch for this node\n",
        "        epoch_i = max(1, int(1.0 / Pi))\n",
        "\n",
        "        # G-set: node can be CH only if it hasn't been CH in this epoch\n",
        "        rounds_since_last_CH = round_num - last_ch_round[i]\n",
        "        in_G = rounds_since_last_CH >= epoch_i\n",
        "\n",
        "        if not in_G:\n",
        "            continue\n",
        "\n",
        "        # LEACH/DEEC threshold\n",
        "        r_mod = round_num % epoch_i\n",
        "        denominator = 1.0 - Pi * r_mod\n",
        "        if denominator <= 0:\n",
        "            threshold = 0.0\n",
        "        else:\n",
        "            threshold = Pi / denominator\n",
        "\n",
        "        # Random selection\n",
        "        if np.random.rand() < threshold:\n",
        "            is_CH[i] = True\n",
        "            last_ch_round[i] = round_num  # update CH history\n",
        "\n",
        "    # Safety: if no CH selected, pick the highest-energy alive node\n",
        "    if not is_CH.any():\n",
        "        alive_idx = np.where(alive_nodes)[0]\n",
        "        if len(alive_idx) > 0:\n",
        "            best = alive_idx[np.argmax(nodes_energy[alive_idx])]\n",
        "            is_CH[best] = True\n",
        "            last_ch_round[best] = round_num\n",
        "\n",
        "    return is_CH\n",
        "\n",
        "\n",
        "def run_deec():\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    avg_energy_history = []\n",
        "    pdr_history = []\n",
        "    alive_nodes_history = []\n",
        "    alive_nodes_per_round = []\n",
        "    num_ch_history = []\n",
        "    reward_history = []\n",
        "    epsilon_history = []\n",
        "    throughput_history = []\n",
        "    pdr_percent_history = []\n",
        "    total_energy_history = []\n",
        "    first_dead_round = None\n",
        "    half_dead_round = None\n",
        "    last_dead_round = None\n",
        "\n",
        "    # Node positions\n",
        "    nodes_pos = [\n",
        "        (random.uniform(0, AREA_SIZE), random.uniform(0, AREA_SIZE))\n",
        "        for _ in range(N_NODES)\n",
        "    ]\n",
        "    sector_ids = assign_static_sectors(nodes_pos, AREA_SIZE, SECTOR_ROWS, SECTOR_COLS)\n",
        "\n",
        "    # Heterogeneous energy initialization (normal & advanced)\n",
        "    nodes_energy, is_advanced = initialize_heterogeneous_energies()\n",
        "\n",
        "    # Track last CH round for each node (for G-set logic)\n",
        "    last_ch_round = np.full(N_NODES, -1_000_000, dtype=int)\n",
        "\n",
        "    for rnd in range(1, ROUNDS + 1):\n",
        "        base_station = get_bs_position(rnd)\n",
        "\n",
        "        alive_nodes = nodes_energy > 0\n",
        "        alive_energy = nodes_energy[alive_nodes]\n",
        "        avg_energy = np.mean(alive_energy) if alive_energy.size > 0 else 0.0\n",
        "\n",
        "        # DEEC CH selection with heterogeneity + G-set\n",
        "        is_CH = select_CHs_deec(\n",
        "            nodes_energy=nodes_energy,\n",
        "            alive_nodes=alive_nodes,\n",
        "            round_num=rnd,\n",
        "            last_ch_round=last_ch_round,\n",
        "            p_opt=P_OPT,\n",
        "            m_fraction_adv=M_FRACTION_ADV,\n",
        "            a_adv=A_ADV_ENERGY\n",
        "        )\n",
        "        chs = np.where(is_CH)[0].tolist()\n",
        "\n",
        "        if len(chs) == 0:\n",
        "            print(f\"[DEEC_BASELINE] No CHs at round {rnd}, skipping communication.\")\n",
        "            avg_energy_history.append(avg_energy)\n",
        "            pdr_history.append(0.0)\n",
        "            alive_nodes_history.append(np.sum(alive_nodes))\n",
        "            num_ch_history.append(0)\n",
        "            reward_history.append(0.0)\n",
        "            epsilon_history.append(0.0)\n",
        "            throughput_history.append(0)\n",
        "            pdr_percent_history.append(0.0)\n",
        "            continue\n",
        "\n",
        "        # Clustering: each alive node joins nearest CH\n",
        "        clusters = [[] for _ in range(len(chs))]\n",
        "        for i in range(N_NODES):\n",
        "            if nodes_energy[i] <= 0:\n",
        "                continue\n",
        "            nearest_ch_idx = min(\n",
        "                range(len(chs)),\n",
        "                key=lambda j: distance(nodes_pos[i], nodes_pos[chs[j]])\n",
        "            )\n",
        "            clusters[nearest_ch_idx].append(i)\n",
        "\n",
        "        # Communication (end-to-end PDR)\n",
        "        nodes_energy, successful_packets, total_packets = radio_comm(\n",
        "            clusters, chs, nodes_energy, nodes_pos, base_station,\n",
        "            tx_power_factor=1.0,\n",
        "            successful_packets=0,\n",
        "            total_packets=0\n",
        "        )\n",
        "\n",
        "        nodes_energy = np.maximum(nodes_energy, 0.0)\n",
        "\n",
        "        avg_e_after, pdr_after, alive_after, cluster_sizes = measure_metrics(\n",
        "            nodes_energy, clusters, chs, successful_packets, total_packets\n",
        "        )\n",
        "\n",
        "        if first_dead_round is None and alive_after < N_NODES:\n",
        "            first_dead_round = rnd\n",
        "        if half_dead_round is None and alive_after <= N_HALF:\n",
        "            half_dead_round = rnd\n",
        "        if alive_after == 0 and last_dead_round is None:\n",
        "            last_dead_round = rnd\n",
        "\n",
        "        alive_nodes_indices = np.where(alive_nodes)[0].tolist()\n",
        "        alive_nodes_per_round.append(alive_nodes_indices)\n",
        "\n",
        "        avg_energy_history.append(avg_e_after)\n",
        "        total_energy_history.append(float(np.sum(nodes_energy)))\n",
        "        pdr_history.append(pdr_after)\n",
        "        alive_nodes_history.append(alive_after)\n",
        "        num_ch_history.append(len(chs))\n",
        "        reward_history.append(0.0)\n",
        "        epsilon_history.append(0.0)\n",
        "        throughput_history.append(successful_packets)\n",
        "        pdr_percent_history.append(\n",
        "            100.0 * successful_packets / (total_packets + 1e-12)\n",
        "        )\n",
        "\n",
        "        if alive_after == 0:\n",
        "            print(f\"[DEEC_BASELINE] All nodes died at round {rnd}\")\n",
        "            break\n",
        "\n",
        "    return (\n",
        "        avg_energy_history, pdr_history, alive_nodes_history, alive_nodes_per_round, num_ch_history,\n",
        "        reward_history, epsilon_history, throughput_history, pdr_percent_history,\n",
        "        first_dead_round, half_dead_round, last_dead_round, sector_ids, nodes_pos, total_energy_history\n",
        "    )\n",
        "\n",
        "print('DEEC baseline algorithm (heterogeneous + G-set) defined!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E6_H8xug7XFL",
      "metadata": {
        "id": "E6_H8xug7XFL"
      },
      "source": [
        "## 6. Baseline Algorithm: Fuzzy C-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FmnW0awq7XFL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmnW0awq7XFL",
        "outputId": "dce5dc4a-54c8-4bdf-bdc3-102b65f11952"
      },
      "outputs": [],
      "source": [
        "def run_fuzzy():\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    avg_energy_history = []\n",
        "    total_energy_history = []\n",
        "    pdr_history = []\n",
        "    alive_nodes_history = []\n",
        "    alive_nodes_per_round = []\n",
        "    num_ch_history = []\n",
        "    reward_history = []\n",
        "    epsilon_history = []\n",
        "    throughput_history = []\n",
        "    pdr_percent_history = []\n",
        "    first_dead_round = None\n",
        "    half_dead_round = None\n",
        "    last_dead_round = None\n",
        "\n",
        "    nodes_pos = np.array([(random.uniform(0, AREA_SIZE), random.uniform(0, AREA_SIZE)) for _ in range(N_NODES)])\n",
        "    sector_ids = assign_static_sectors(nodes_pos, AREA_SIZE, SECTOR_ROWS, SECTOR_COLS)\n",
        "\n",
        "    nodes_energy = np.array([INIT_ENERGY] * N_NODES)\n",
        "\n",
        "    m = 2.0\n",
        "    error = 1e-5\n",
        "    maxiter = 1000\n",
        "\n",
        "    for rnd in range(1, ROUNDS + 1):\n",
        "        base_station = get_bs_position(rnd)\n",
        "\n",
        "        cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
        "            data=nodes_pos.T,\n",
        "            c=NUM_CLUSTERS,\n",
        "            m=m,\n",
        "            error=error,\n",
        "            maxiter=maxiter,\n",
        "            init=None,\n",
        "            seed=SEED\n",
        "        )\n",
        "\n",
        "        labels = np.argmax(u, axis=0)\n",
        "        clusters = [[] for _ in range(NUM_CLUSTERS)]\n",
        "        for i, lbl in enumerate(labels):\n",
        "            if nodes_energy[i] > 0:\n",
        "                clusters[lbl].append(i)\n",
        "\n",
        "        chs = [None] * NUM_CLUSTERS\n",
        "        for cidx, members in enumerate(clusters):\n",
        "            alive_members = [n for n in members if nodes_energy[n] > 0]\n",
        "            if not alive_members:\n",
        "                continue\n",
        "            energies = np.array([nodes_energy[n] for n in alive_members])\n",
        "            if energies.sum() == 0:\n",
        "                chosen = random.choice(alive_members)\n",
        "            else:\n",
        "                probs = energies / energies.sum()\n",
        "                chosen = np.random.choice(alive_members, p=probs)\n",
        "            chs[cidx] = chosen\n",
        "\n",
        "        clusters = [c for c in clusters if c]\n",
        "        chs = [ch for ch in chs if ch is not None]\n",
        "\n",
        "        if len(chs) == 0:\n",
        "            alive_nodes = [i for i in range(N_NODES) if nodes_energy[i] > 0]\n",
        "            if alive_nodes:\n",
        "                chosen = random.choice(alive_nodes)\n",
        "                chs = [chosen]\n",
        "                clusters = [[chosen]]\n",
        "\n",
        "        nodes_energy, successful_packets, total_packets = radio_comm(\n",
        "            clusters, chs, nodes_energy, nodes_pos, base_station, tx_power_factor=1.0,\n",
        "            successful_packets=0, total_packets=0\n",
        "        )\n",
        "        nodes_energy = np.maximum(nodes_energy, 0.0)\n",
        "        avg_e_after, pdr_after, alive_after, cluster_sizes = measure_metrics(\n",
        "            nodes_energy, clusters, chs, successful_packets, total_packets\n",
        "        )\n",
        "\n",
        "        if first_dead_round is None and alive_after < N_NODES:\n",
        "            first_dead_round = rnd\n",
        "        if half_dead_round is None and alive_after <= N_HALF:\n",
        "            half_dead_round = rnd\n",
        "        if alive_after == 0 and last_dead_round is None:\n",
        "            last_dead_round = rnd\n",
        "\n",
        "        alive_nodes = nodes_energy > 0\n",
        "        alive_nodes_indices = np.where(alive_nodes)[0].tolist()\n",
        "        alive_nodes_per_round.append(alive_nodes_indices)\n",
        "        avg_energy_history.append(avg_e_after)\n",
        "        total_energy_history.append(float(np.sum(nodes_energy)))\n",
        "        pdr_history.append(pdr_after)\n",
        "        alive_nodes_history.append(alive_after)\n",
        "        num_ch_history.append(len(chs))\n",
        "        reward_history.append(0.0)\n",
        "        epsilon_history.append(0.0)\n",
        "        throughput_history.append(successful_packets)\n",
        "        pdr_percent_history.append(100.0 * successful_packets / (total_packets + 1e-12))\n",
        "\n",
        "        if alive_after == 0:\n",
        "            print(f\"[FUZZY_C_MEANS_BASELINE] All nodes died at round {rnd}\")\n",
        "            break\n",
        "\n",
        "    return (\n",
        "        avg_energy_history, pdr_history, alive_nodes_history, alive_nodes_per_round, num_ch_history,\n",
        "        reward_history, epsilon_history, throughput_history, pdr_percent_history,\n",
        "        first_dead_round, half_dead_round, last_dead_round, sector_ids, nodes_pos, total_energy_history\n",
        "    )\n",
        "\n",
        "print('Fuzzy C-Means baseline algorithm defined!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90oLH6GZ7XFM",
      "metadata": {
        "id": "90oLH6GZ7XFM"
      },
      "source": [
        "## 6. Baseline Algorithm: PSO + GA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hEgsoJWU7XFM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEgsoJWU7XFM",
        "outputId": "516bca0c-3a42-4e5a-9c1b-c4ac487be14a"
      },
      "outputs": [],
      "source": [
        "def run_pso():\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    # Histories\n",
        "    avg_energy_history = []\n",
        "    total_energy_history = []\n",
        "    pdr_history = []\n",
        "    alive_nodes_history = []\n",
        "    alive_nodes_per_round = []\n",
        "    num_ch_history = []\n",
        "    reward_history = []\n",
        "    epsilon_history = []\n",
        "    throughput_history = []\n",
        "    pdr_percent_history = []\n",
        "    first_dead_round = None\n",
        "    half_dead_round = None\n",
        "    last_dead_round = None\n",
        "\n",
        "    # Network initialization\n",
        "    nodes_pos = np.array([\n",
        "        (random.uniform(0, AREA_SIZE), random.uniform(0, AREA_SIZE))\n",
        "        for _ in range(N_NODES)\n",
        "    ])\n",
        "    sector_ids = assign_static_sectors(nodes_pos, AREA_SIZE, SECTOR_ROWS, SECTOR_COLS)\n",
        "\n",
        "    nodes_energy = np.array([INIT_ENERGY] * N_NODES, dtype=float)\n",
        "\n",
        "    # PSO+GA hyperparameters (tune as needed)\n",
        "    dim = 2 * NUM_CLUSTERS              # each cluster has (x, y)\n",
        "    POP = PSO_POP                       # population size\n",
        "    W_inertia = W                       # inertia weight (e.g., 0.7)\n",
        "    C1_pbest = C1                       # cognitive weight (e.g., 1.5)\n",
        "    C2_gbest = C2                       # social weight (e.g., 1.5)\n",
        "    GA_CROSSOVER_RATE = 0.7\n",
        "    GA_MUTATION_RATE = 0.1\n",
        "    GA_MUTATION_STD = AREA_SIZE * 0.02  # mutation step size (2% of area)\n",
        "\n",
        "    # Initialize particles: random centroids in field\n",
        "    particles = np.random.uniform(\n",
        "        low=0.0, high=AREA_SIZE,\n",
        "        size=(POP, dim)  # shape: (POP, 2*K)\n",
        "    )\n",
        "    velocities = np.zeros_like(particles)\n",
        "\n",
        "    # Personal bests\n",
        "    pbest = particles.copy()\n",
        "    pbest_scores = np.full(POP, np.inf)\n",
        "\n",
        "    # Global best\n",
        "    gbest = None\n",
        "    gbest_score = np.inf\n",
        "\n",
        "    def decode_particle_to_chs(centroids, nodes_pos, nodes_energy, base_station):\n",
        "        \"\"\"\n",
        "        From a particle (centroids), build clusters and pick CHs:\n",
        "        - Assign each alive node to nearest centroid.\n",
        "        - For each cluster, choose CH as node with highest energy;\n",
        "          tie-break by closeness to centroid.\n",
        "        \"\"\"\n",
        "        K = NUM_CLUSTERS\n",
        "        centroids = centroids.reshape(K, 2)\n",
        "\n",
        "        # Assign nodes to nearest centroid\n",
        "        clusters = [[] for _ in range(K)]\n",
        "        for i in range(N_NODES):\n",
        "            if nodes_energy[i] <= 0:\n",
        "                continue\n",
        "            dists = np.linalg.norm(nodes_pos[i] - centroids, axis=1)\n",
        "            nearest = int(np.argmin(dists))\n",
        "            clusters[nearest].append(i)\n",
        "\n",
        "        chs = []\n",
        "        for k in range(K):\n",
        "            cluster_nodes = clusters[k]\n",
        "            if not cluster_nodes:\n",
        "                # fallback: pick the highest-energy node globally\n",
        "                chs.append(int(np.argmax(nodes_energy)))\n",
        "                continue\n",
        "            # pick highest-energy node in this cluster\n",
        "            max_e = max(nodes_energy[n] for n in cluster_nodes)\n",
        "            cand = [n for n in cluster_nodes if nodes_energy[n] == max_e]\n",
        "            if len(cand) > 1:\n",
        "                # tie-break: closest to centroid\n",
        "                ck = centroids[k]\n",
        "                best = min(cand, key=lambda n: np.linalg.norm(nodes_pos[n] - ck))\n",
        "                chs.append(best)\n",
        "            else:\n",
        "                chs.append(cand[0])\n",
        "\n",
        "        return clusters, chs\n",
        "\n",
        "    def fitness_function(centroids, nodes_pos, nodes_energy, base_station):\n",
        "        \"\"\"\n",
        "        Multi-criteria fitness:\n",
        "        1) Intra-cluster distance (sum of distances node-CH)\n",
        "        2) CH energy penalty (prefer high-energy CHs → penalize low avg CH energy)\n",
        "        3) Distance of CHs to base station\n",
        "        Lower is better.\n",
        "        \"\"\"\n",
        "        clusters, chs = decode_particle_to_chs(\n",
        "            centroids, nodes_pos, nodes_energy, base_station\n",
        "        )\n",
        "\n",
        "        # 1) Intra-cluster distance\n",
        "        intra_dist = 0.0\n",
        "        for cidx, cluster_nodes in enumerate(clusters):\n",
        "            ch = chs[cidx]\n",
        "            for node in cluster_nodes:\n",
        "                intra_dist += np.linalg.norm(nodes_pos[node] - nodes_pos[ch])\n",
        "\n",
        "        # 2) CH energy penalty (we want CH energies large)\n",
        "        ch_energies = nodes_energy[chs]\n",
        "        avg_ch_energy = np.mean(ch_energies) if len(ch_energies) > 0 else 0.0\n",
        "        # penalty is inverse of energy (avoid division by zero)\n",
        "        energy_penalty = 1.0 / (avg_ch_energy + 1e-9)\n",
        "\n",
        "        # 3) CH to BS distance\n",
        "        bs_dist = 0.0\n",
        "        bs_pos = np.array(base_station)\n",
        "        for ch in chs:\n",
        "            bs_dist += np.linalg.norm(nodes_pos[ch] - bs_pos)\n",
        "\n",
        "        # Weights (tuneable)\n",
        "        w1 = 1.0     # intra-cluster distance\n",
        "        w2 = 100.0   # CH energy penalty\n",
        "        w3 = 0.1     # CH-BS distance\n",
        "\n",
        "        fitness = w1 * intra_dist + w2 * energy_penalty + w3 * bs_dist\n",
        "        return fitness\n",
        "\n",
        "    for rnd in range(1, ROUNDS + 1):\n",
        "        base_station = get_bs_position(rnd)\n",
        "\n",
        "        # ---------------\n",
        "        # PSO Evaluation\n",
        "        # ---------------\n",
        "        scores = np.zeros(POP)\n",
        "        for pidx in range(POP):\n",
        "            # Make sure centroids stay in field\n",
        "            particles[pidx] = np.clip(particles[pidx], 0.0, AREA_SIZE)\n",
        "            score = fitness_function(\n",
        "                particles[pidx], nodes_pos, nodes_energy, base_station\n",
        "            )\n",
        "            scores[pidx] = score\n",
        "\n",
        "            # Update personal best\n",
        "            if score < pbest_scores[pidx]:\n",
        "                pbest_scores[pidx] = score\n",
        "                pbest[pidx] = particles[pidx].copy()\n",
        "\n",
        "            # Update global best\n",
        "            if score < gbest_score:\n",
        "                gbest_score = score\n",
        "                gbest = particles[pidx].copy()\n",
        "\n",
        "        # ---------------\n",
        "        # PSO Update\n",
        "        # ---------------\n",
        "        for pidx in range(POP):\n",
        "            r1 = np.random.rand(dim)\n",
        "            r2 = np.random.rand(dim)\n",
        "            velocities[pidx] = (\n",
        "                W_inertia * velocities[pidx]\n",
        "                + C1_pbest * r1 * (pbest[pidx] - particles[pidx])\n",
        "                + C2_gbest * r2 * (gbest - particles[pidx])\n",
        "            )\n",
        "            particles[pidx] += velocities[pidx]\n",
        "            particles[pidx] = np.clip(particles[pidx], 0.0, AREA_SIZE)\n",
        "\n",
        "        # ---------------\n",
        "        # GA: Crossover & Mutation on the best half\n",
        "        # ---------------\n",
        "        # Select best half by fitness\n",
        "        best_indices = np.argsort(scores)[:POP // 2]\n",
        "\n",
        "        # Crossover pairs\n",
        "        for i in range(0, len(best_indices), 2):\n",
        "            if i + 1 >= len(best_indices):\n",
        "                break\n",
        "            idx1 = best_indices[i]\n",
        "            idx2 = best_indices[i + 1]\n",
        "\n",
        "            parent1 = particles[idx1].copy()\n",
        "            parent2 = particles[idx2].copy()\n",
        "\n",
        "            if random.random() < GA_CROSSOVER_RATE:\n",
        "                point = random.randint(1, dim - 1)\n",
        "                child1 = np.concatenate([parent1[:point], parent2[point:]])\n",
        "                child2 = np.concatenate([parent2[:point], parent1[point:]])\n",
        "            else:\n",
        "                child1, child2 = parent1, parent2\n",
        "\n",
        "            # Mutation: small Gaussian noise on some dimensions\n",
        "            for child in (child1, child2):\n",
        "                if random.random() < GA_MUTATION_RATE:\n",
        "                    mut_dims = np.random.rand(dim) < 0.1  # 10% of dims\n",
        "                    noise = np.random.normal(0.0, GA_MUTATION_STD, size=dim)\n",
        "                    child[mut_dims] += noise[mut_dims]\n",
        "                    child[:] = np.clip(child, 0.0, AREA_SIZE)\n",
        "\n",
        "            # Replace worst individuals with children\n",
        "            worst_indices = np.argsort(scores)[-2:]\n",
        "            particles[worst_indices[0]] = child1\n",
        "            particles[worst_indices[1]] = child2\n",
        "\n",
        "        # ---------------\n",
        "        # Use global best centroids to define actual CHs and clusters\n",
        "        # ---------------\n",
        "        if gbest is None:\n",
        "            # just in case, but should not happen\n",
        "            gbest = particles[0].copy()\n",
        "\n",
        "        clusters, chs = decode_particle_to_chs(\n",
        "            gbest, nodes_pos, nodes_energy, base_station\n",
        "        )\n",
        "\n",
        "        # ---------------\n",
        "        # Radio communication & metrics\n",
        "        # ---------------\n",
        "        nodes_energy, successful_packets, total_packets = radio_comm(\n",
        "            clusters, chs, nodes_energy, nodes_pos, base_station, tx_power_factor=1.0\n",
        "        )\n",
        "        nodes_energy = np.maximum(nodes_energy, 0.0)\n",
        "\n",
        "        avg_e_after, pdr_after, alive_after, cluster_sizes = measure_metrics(\n",
        "            nodes_energy, clusters, chs, successful_packets, total_packets\n",
        "        )\n",
        "\n",
        "        # ---------------\n",
        "        # Lifetime tracking\n",
        "        # ---------------\n",
        "        if first_dead_round is None and alive_after < N_NODES:\n",
        "            first_dead_round = rnd\n",
        "        if half_dead_round is None and alive_after <= N_HALF:\n",
        "            half_dead_round = rnd\n",
        "        if alive_after == 0 and last_dead_round is None:\n",
        "            last_dead_round = rnd\n",
        "\n",
        "        # ---------------\n",
        "        # Logging\n",
        "        # ---------------\n",
        "        alive_nodes = nodes_energy > 0\n",
        "        alive_nodes_indices = np.where(alive_nodes)[0].tolist()\n",
        "        alive_nodes_per_round.append(alive_nodes_indices)\n",
        "        avg_energy_history.append(avg_e_after)\n",
        "        total_energy_history.append(float(np.sum(nodes_energy)))\n",
        "        pdr_history.append(pdr_after)\n",
        "        alive_nodes_history.append(alive_after)\n",
        "        num_ch_history.append(len(chs))\n",
        "        reward_history.append(0.0)      # no RL reward here\n",
        "        epsilon_history.append(0.0)     # no epsilon-greedy here\n",
        "        throughput_history.append(successful_packets)\n",
        "        pdr_percent_history.append(\n",
        "            100.0 * successful_packets / (total_packets + 1e-12)\n",
        "        )\n",
        "\n",
        "        if alive_after == 0:\n",
        "            print(f\"[PSO_GA] All nodes died at round {rnd}\")\n",
        "            break\n",
        "\n",
        "    return (\n",
        "        avg_energy_history, pdr_history, alive_nodes_history, alive_nodes_per_round, num_ch_history,\n",
        "        reward_history, epsilon_history, throughput_history, pdr_percent_history,\n",
        "        first_dead_round, half_dead_round, last_dead_round, sector_ids, nodes_pos, total_energy_history\n",
        "    )\n",
        "\n",
        "print('PSO+GA clustering baseline (literature-style) defined!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N1LkicfP7XFN",
      "metadata": {
        "id": "N1LkicfP7XFN"
      },
      "source": [
        "## 6. Baseline Algorithm: ACO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd4oHVFq7XFN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd4oHVFq7XFN",
        "outputId": "16db0233-e43d-41f6-f42d-75f76b458541"
      },
      "outputs": [],
      "source": [
        "def run_aco():\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    # Histories\n",
        "    avg_energy_history, pdr_history, alive_nodes_history = [], [], []\n",
        "    num_ch_history, reward_history, epsilon_history = [], [], []\n",
        "    throughput_history, pdr_percent_history = [], []\n",
        "    alive_nodes_per_round = []\n",
        "    total_energy_history = []\n",
        "    first_dead_round = half_dead_round = last_dead_round = None\n",
        "\n",
        "    # Network initialization\n",
        "    nodes_pos = np.array([\n",
        "        (random.uniform(0, AREA_SIZE), random.uniform(0, AREA_SIZE))\n",
        "        for _ in range(N_NODES)\n",
        "    ])\n",
        "    sector_ids = assign_static_sectors(nodes_pos, AREA_SIZE, SECTOR_ROWS, SECTOR_COLS)\n",
        "\n",
        "    nodes_energy = np.array([INIT_ENERGY] * N_NODES, dtype=float)\n",
        "\n",
        "    # ACO parameters (assumed already defined globally)\n",
        "    # ACO_ALPHA, ACO_BETA, RHO, ACO_Q, ANTS, NUM_CLUSTERS\n",
        "\n",
        "    # Initial pheromone and heuristic\n",
        "    pheromone = np.ones(N_NODES, dtype=float)\n",
        "    heuristic = np.zeros(N_NODES, dtype=float)\n",
        "\n",
        "    for rnd in range(1, ROUNDS + 1):\n",
        "        base_station = get_bs_position(rnd)\n",
        "        # -------------------------\n",
        "        # Alive nodes\n",
        "        # -------------------------\n",
        "        alive_nodes = [i for i in range(N_NODES) if nodes_energy[i] > 0]\n",
        "        if not alive_nodes:\n",
        "            print(f\"[ACO_BASELINE] All nodes died at round {rnd}\")\n",
        "            break\n",
        "\n",
        "        alive_arr = np.array(alive_nodes, dtype=int)\n",
        "\n",
        "        # -------------------------\n",
        "        # Heuristic update\n",
        "        # heuristic[i] = E_i / d(i, BS)\n",
        "        # -------------------------\n",
        "        for i in alive_arr:\n",
        "            d_bs = np.linalg.norm(nodes_pos[i] - base_station)\n",
        "            heuristic[i] = nodes_energy[i] / (d_bs + 1e-6)\n",
        "\n",
        "        all_solutions = []\n",
        "        fitness_scores = []\n",
        "\n",
        "        # -------------------------\n",
        "        # Ant colony construction\n",
        "        # -------------------------\n",
        "        for _ in range(ANTS):\n",
        "            # Raw probabilities over alive nodes\n",
        "            probs = (pheromone[alive_arr] ** ACO_ALPHA) * (heuristic[alive_arr] ** ACO_BETA)\n",
        "            probs_sum = probs.sum()\n",
        "\n",
        "            if probs_sum <= 0:\n",
        "                # All zero → use uniform probability\n",
        "                probs = np.ones_like(probs, dtype=float) / len(probs)\n",
        "            else:\n",
        "                probs = probs / probs_sum\n",
        "\n",
        "            num_chs = min(NUM_CLUSTERS, len(alive_arr))\n",
        "\n",
        "            if len(alive_arr) <= NUM_CLUSTERS:\n",
        "                ch_indices = alive_arr.copy()\n",
        "            else:\n",
        "                # Ensure enough non-zero probabilities for sampling without replacement\n",
        "                positive_mask = probs > 0\n",
        "                num_positive = int(np.sum(positive_mask))\n",
        "\n",
        "                if num_positive < num_chs:\n",
        "                    # Fallback: uniform random choice among all alive nodes\n",
        "                    ch_indices = np.random.choice(\n",
        "                        alive_arr, size=num_chs, replace=False\n",
        "                    )\n",
        "                else:\n",
        "                    # Restrict to positive-probability candidates\n",
        "                    alive_pos = alive_arr[positive_mask]\n",
        "                    probs_pos = probs[positive_mask]\n",
        "                    probs_pos = probs_pos / probs_pos.sum()  # renormalize\n",
        "\n",
        "                    ch_indices = np.random.choice(\n",
        "                        alive_pos, size=num_chs, replace=False, p=probs_pos\n",
        "                    )\n",
        "\n",
        "            # -------------------------\n",
        "            # Build clusters: assign each alive node to nearest CH\n",
        "            # -------------------------\n",
        "            clusters = [[] for _ in range(len(ch_indices))]\n",
        "            ch_positions = nodes_pos[ch_indices]\n",
        "\n",
        "            for i in alive_arr:\n",
        "                dists = np.linalg.norm(ch_positions - nodes_pos[i], axis=1)\n",
        "                closest = int(np.argmin(dists))\n",
        "                clusters[closest].append(i)\n",
        "\n",
        "            # -------------------------\n",
        "            # Fitness (literature-style)\n",
        "            # 1) Intra-cluster distance\n",
        "            # 2) CH energy penalty (prefer higher-energy CHs)\n",
        "            # 3) CH–BS distance\n",
        "            # -------------------------\n",
        "            total_dist = 0.0\n",
        "            for i in alive_arr:\n",
        "                dists = np.linalg.norm(ch_positions - nodes_pos[i], axis=1)\n",
        "                total_dist += np.min(dists)\n",
        "\n",
        "            # CH energy\n",
        "            ch_energies = nodes_energy[ch_indices]\n",
        "            avg_ch_energy = np.mean(ch_energies) if len(ch_energies) > 0 else 0.0\n",
        "            energy_penalty = 1.0 / (avg_ch_energy + 1e-6)\n",
        "\n",
        "            # CH–BS distance\n",
        "            bs_dists = np.linalg.norm(ch_positions - base_station, axis=1)\n",
        "            ch_bs_dist = np.sum(bs_dists)\n",
        "\n",
        "            # Weights (tune as needed)\n",
        "            w1, w2, w3 = 1.0, 100.0, 0.1\n",
        "            fitness = w1 * total_dist + w2 * energy_penalty + w3 * ch_bs_dist\n",
        "\n",
        "            all_solutions.append((clusters, ch_indices))\n",
        "            fitness_scores.append(fitness)\n",
        "\n",
        "        # -------------------------\n",
        "        # Select best solution for this round\n",
        "        # -------------------------\n",
        "        best_idx = int(np.argmin(fitness_scores))\n",
        "        best_clusters, best_chs = all_solutions[best_idx]\n",
        "\n",
        "        # Remove empty clusters for safety\n",
        "        valid_clusters, valid_chs = [], []\n",
        "        for ci, cluster in enumerate(best_clusters):\n",
        "            if cluster:\n",
        "                valid_clusters.append(cluster)\n",
        "                if ci < len(best_chs):\n",
        "                    valid_chs.append(int(best_chs[ci]))\n",
        "\n",
        "        if not valid_chs:\n",
        "            # Fallback: choose one random alive node as CH\n",
        "            chosen = random.choice(alive_nodes)\n",
        "            valid_chs = [chosen]\n",
        "            valid_clusters = [[chosen]]\n",
        "\n",
        "        best_clusters, best_chs = valid_clusters, valid_chs\n",
        "\n",
        "        # -------------------------\n",
        "        # Pheromone update\n",
        "        # -------------------------\n",
        "        pheromone *= (1 - RHO)  # evaporation\n",
        "        best_fit = fitness_scores[best_idx]\n",
        "        for ch in best_chs:\n",
        "            pheromone[ch] += ACO_Q / (best_fit + 1e-6)\n",
        "\n",
        "        # -------------------------\n",
        "        # Radio communication\n",
        "        # -------------------------\n",
        "        nodes_energy, successful_packets, total_packets = radio_comm(\n",
        "            best_clusters,\n",
        "            best_chs,\n",
        "            nodes_energy,\n",
        "            nodes_pos,\n",
        "            base_station,\n",
        "            tx_power_factor=1.0,\n",
        "            successful_packets=0,\n",
        "            total_packets=0\n",
        "        )\n",
        "        nodes_energy = np.maximum(nodes_energy, 0.0)\n",
        "\n",
        "        avg_e_after, pdr_after, alive_after, _ = measure_metrics(\n",
        "            nodes_energy, best_clusters, best_chs, successful_packets, total_packets\n",
        "        )\n",
        "\n",
        "        # -------------------------\n",
        "        # Lifetime tracking\n",
        "        # -------------------------\n",
        "        if first_dead_round is None and alive_after < N_NODES:\n",
        "            first_dead_round = rnd\n",
        "        if half_dead_round is None and alive_after <= N_HALF:\n",
        "            half_dead_round = rnd\n",
        "        if alive_after == 0 and last_dead_round is None:\n",
        "            last_dead_round = rnd\n",
        "\n",
        "        # -------------------------\n",
        "        # Logging\n",
        "        # -------------------------\n",
        "        alive_nodes = nodes_energy > 0\n",
        "        alive_nodes_indices = np.where(alive_nodes)[0].tolist()\n",
        "        alive_nodes_per_round.append(alive_nodes_indices)\n",
        "        avg_energy_history.append(avg_e_after)\n",
        "        total_energy_history.append(float(np.sum(nodes_energy)))\n",
        "        pdr_history.append(pdr_after)\n",
        "        alive_nodes_history.append(alive_after)\n",
        "        num_ch_history.append(len(best_chs))\n",
        "        reward_history.append(0.0)      # no RL here\n",
        "        epsilon_history.append(0.0)     # no RL here\n",
        "        throughput_history.append(successful_packets)\n",
        "        pdr_percent_history.append(\n",
        "            100.0 * successful_packets / (total_packets + 1e-12)\n",
        "        )\n",
        "\n",
        "        if alive_after == 0:\n",
        "            print(f\"[ACO_BASELINE] All nodes died at round {rnd}\")\n",
        "            break\n",
        "\n",
        "    return (\n",
        "        avg_energy_history,\n",
        "        pdr_history,\n",
        "        alive_nodes_history,\n",
        "        alive_nodes_per_round,\n",
        "        num_ch_history,\n",
        "        reward_history,\n",
        "        epsilon_history,\n",
        "        throughput_history,\n",
        "        pdr_percent_history,\n",
        "        first_dead_round,\n",
        "        half_dead_round,\n",
        "        last_dead_round,\n",
        "        sector_ids,\n",
        "        nodes_pos,\n",
        "        total_energy_history\n",
        "    )\n",
        "\n",
        "print('ACO baseline algorithm defined (robust & literature-style)!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bKoIj3nr7XFO",
      "metadata": {
        "id": "bKoIj3nr7XFO"
      },
      "source": [
        "## 7. Experiment Runner\n",
        "\n",
        "Run all 6 algorithms and collect results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bw5l9Tr67XFO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw5l9Tr67XFO",
        "outputId": "523ca9bd-02e5-41c9-86aa-ef31d952e29b"
      },
      "outputs": [],
      "source": [
        "METHODS = {\n",
        "    'LEACH_BASELINE': run_leach,\n",
        "    'DEEC_BASELINE': run_deec,\n",
        "    'FUZZY_C_MEANS_BASELINE': run_fuzzy,\n",
        "    'PSO_BASELINE': run_pso,\n",
        "    'ACO_BASELINE': run_aco,\n",
        "    'RLHC_PROPOSED': run_proposed,\n",
        "}\n",
        "\n",
        "colors = ['blue', 'red', 'green', 'gold', 'orange', 'black']\n",
        "results = {}\n",
        "\n",
        "print(f\"Starting experiments...\\nSimulate for the rounds: {ROUNDS} \\n\")\n",
        "for method_name, method_func in METHODS.items():\n",
        "    print(f\"Running method: {method_name}\")\n",
        "    (\n",
        "        avg_energy_history, pdr_history, alive_nodes_history, alive_nodes_per_round, num_ch_history,\n",
        "        reward_history, epsilon_history, throughput_history, pdr_percent_history,\n",
        "        first_dead_round, half_dead_round, last_dead_round, sector_ids, nodes_pos, total_energy_history\n",
        "    ) = method_func()\n",
        "\n",
        "    results[method_name] = {\n",
        "        \"avg_energy_history\": avg_energy_history,\n",
        "        \"pdr_history\": pdr_history,\n",
        "        \"alive_nodes_history\": alive_nodes_history,\n",
        "        \"alive_nodes_per_round\": alive_nodes_per_round,\n",
        "        \"num_ch_history\": num_ch_history,\n",
        "        \"reward_history\": reward_history,\n",
        "        \"epsilon_history\": epsilon_history,\n",
        "        \"throughput_history\": throughput_history,\n",
        "        \"pdr_percent_history\": pdr_percent_history,\n",
        "        \"first_dead_round\": first_dead_round,\n",
        "        \"half_dead_round\": half_dead_round,\n",
        "        \"sector_ids\": sector_ids,\n",
        "        \"nodes_pos\": nodes_pos,\n",
        "        \"total_energy_history\": total_energy_history,\n",
        "        \"last_dead_round\": ROUNDS\n",
        "    }\n",
        "\n",
        "print(\"\\nAll experiments completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WNYK5jD37XFO",
      "metadata": {
        "id": "WNYK5jD37XFO"
      },
      "source": [
        "## 8. Visualization\n",
        "\n",
        "### Plot 1: Dead Nodes vs Number of Rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e761d463",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e761d463",
        "outputId": "ec237801-313f-4285-d6e7-033b4d1b4ec9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def compute_sector_lifetimes(alive_nodes_per_round, sector_ids, num_sectors):\n",
        "    lifetimes = [None] * num_sectors  # last round sector had at least 1 alive node\n",
        "\n",
        "    for rnd, alive_nodes in enumerate(alive_nodes_per_round, start=1):\n",
        "        if not alive_nodes:\n",
        "            continue\n",
        "        alive_arr = np.array(alive_nodes, dtype=int)\n",
        "        alive_sectors = np.unique(sector_ids[alive_arr])\n",
        "        for s in alive_sectors:\n",
        "            lifetimes[s] = rnd  # update last active round\n",
        "    return lifetimes\n",
        "\n",
        "rows_list = []\n",
        "for method_name, res in results.items():\n",
        "    alive_nodes_per_round = res[\"alive_nodes_per_round\"]\n",
        "\n",
        "    # get these from results instead of globals\n",
        "    sector_ids = res[\"sector_ids\"]\n",
        "    num_sectors = len(np.unique(sector_ids))   # or set num_sectors = 9 earlier and store it\n",
        "\n",
        "    lifetimes = compute_sector_lifetimes(alive_nodes_per_round, sector_ids, num_sectors)\n",
        "\n",
        "    row = {\"Method\": method_name}\n",
        "    for s, life in enumerate(lifetimes):\n",
        "        row[f\"Sector {s} lifetime (round)\"] = life\n",
        "    rows_list.append(row)\n",
        "\n",
        "sector_life_table = pd.DataFrame(rows_list)\n",
        "print(\"\\nSector lifetime summary table:\")\n",
        "print(sector_life_table.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b054bcc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b054bcc2",
        "outputId": "41e36563-9387-446c-c8b0-9372fea36e92"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# If you already have sector_life_table from your code:\n",
        "# sector_life_table = pd.DataFrame(rows_list)\n",
        "\n",
        "# --- Basic bar chart for each method ---\n",
        "for idx, row in sector_life_table.iterrows():\n",
        "    method_name = row[\"Method\"]\n",
        "\n",
        "    # Extract only the sector columns\n",
        "    sector_cols = [c for c in sector_life_table.columns if c.startswith(\"Sector\")]\n",
        "    lifetimes = row[sector_cols].values.astype(float)\n",
        "\n",
        "    # Create x labels: Sector 0, Sector 1, ...\n",
        "    x = np.arange(len(sector_cols))\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(x, lifetimes, color=\"skyblue\", edgecolor=\"black\")\n",
        "    plt.xticks(x, sector_cols, rotation=45, ha=\"right\")\n",
        "    plt.ylabel(\"Lifetime (round)\")\n",
        "    plt.title(f\"Sector Lifetime per Sector - {method_name}\")\n",
        "    plt.tight_layout()\n",
        "    plt.grid(axis=\"y\", alpha=0.3)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "387509f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "387509f3",
        "outputId": "33ea576f-f3fd-4ef7-e846-ccca1033a2ec"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "for idx, row in sector_life_table.iterrows():\n",
        "    method_name = row[\"Method\"]\n",
        "    res = results[method_name]\n",
        "\n",
        "    nodes_pos = np.array(res[\"nodes_pos\"])\n",
        "    sector_ids = np.array(res[\"sector_ids\"])\n",
        "\n",
        "    # get sector lifetimes from sector_life_table\n",
        "    row = sector_life_table[sector_life_table[\"Method\"] == method_name].iloc[0]\n",
        "    sector_cols = [c for c in sector_life_table.columns if c.startswith(\"Sector\")]\n",
        "    sector_lifetimes = row[sector_cols].values.astype(float)\n",
        "\n",
        "    # dimensions\n",
        "    cell_w = AREA_SIZE / SECTOR_COLS\n",
        "    cell_h = AREA_SIZE / SECTOR_ROWS\n",
        "\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # -----------------------------\n",
        "    # Shade sectors that died before last round\n",
        "    # -----------------------------\n",
        "    sector_index = 0\n",
        "    for r in range(SECTOR_ROWS):\n",
        "        for c in range(SECTOR_COLS):\n",
        "            lifetime = sector_lifetimes[sector_index]\n",
        "\n",
        "            # if sector did NOT survive till last round, shade it grey\n",
        "            if lifetime < ROUNDS:\n",
        "                rect = Rectangle(\n",
        "                    (c * cell_w, r * cell_h),  # bottom-left corner\n",
        "                    cell_w,\n",
        "                    cell_h,\n",
        "                    facecolor=\"lightgrey\",\n",
        "                    alpha=0.5,\n",
        "                    edgecolor=\"none\",\n",
        "                    zorder=0  # behind other elements\n",
        "                )\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "            sector_index += 1\n",
        "\n",
        "    # -----------------------------\n",
        "    # Scatter plot of nodes colored by sector\n",
        "    # -----------------------------\n",
        "    sc = plt.scatter(\n",
        "        nodes_pos[:, 0],\n",
        "        nodes_pos[:, 1],\n",
        "        c=sector_ids,\n",
        "        cmap=\"tab10\",\n",
        "        s=40,\n",
        "        edgecolor=\"black\",\n",
        "        zorder=2\n",
        "    )\n",
        "\n",
        "    # -----------------------------\n",
        "    # Base Station\n",
        "    # -----------------------------\n",
        "    if BS_MODE != \"fixed\":\n",
        "        # Make sure BS_TRAJECTORY is a numpy array\n",
        "        bs_traj = np.array(BS_TRAJECTORY)\n",
        "\n",
        "        if BS_MODE == \"mobile_circle\":\n",
        "            # Plot BS path as a line\n",
        "            plt.plot(\n",
        "                bs_traj[:, 0],\n",
        "                bs_traj[:, 1],\n",
        "                linestyle=\"-\",\n",
        "                color=\"red\",\n",
        "                linewidth=1.5,\n",
        "                label=\"BS path\",\n",
        "                zorder=3\n",
        "            )\n",
        "\n",
        "        if BS_MODE == \"mobile_random\":\n",
        "            # Plot BS path as a line\n",
        "            plt.plot(\n",
        "                bs_traj[:, 0],\n",
        "                bs_traj[:, 1],\n",
        "                linestyle=\"--\",\n",
        "                color=\"red\",\n",
        "                linewidth=0.2,\n",
        "                label=\"BS path\",\n",
        "                zorder=2\n",
        "            )\n",
        "\n",
        "        # if BS_MODE == \"mobile_random\":\n",
        "        #     # Only draw points (no connecting line)\n",
        "        #     plt.scatter(\n",
        "        #         bs_traj[:, 0],\n",
        "        #         bs_traj[:, 1],\n",
        "        #         marker=\"*\",\n",
        "        #         s=120,\n",
        "        #         color=\"red\",\n",
        "        #         edgecolor=\"black\",\n",
        "        #         label=\"BS positions\",\n",
        "        #         zorder=1\n",
        "        #     )\n",
        "\n",
        "    else:\n",
        "        # Fixed BS for\n",
        "        base_station = BASE_STATION_FIXED\n",
        "        plt.scatter(\n",
        "            base_station[0], base_station[1],\n",
        "            marker=\"^\",\n",
        "            s=200,\n",
        "            color=\"red\",\n",
        "            edgecolor=\"black\",\n",
        "            label=\"Base Station\",\n",
        "            zorder=3\n",
        "        )\n",
        "\n",
        "    plt.colorbar(sc, label=\"Sector ID\")\n",
        "\n",
        "    # -----------------------------\n",
        "    # Draw grid lines\n",
        "    # -----------------------------\n",
        "    for c in range(SECTOR_COLS + 1):\n",
        "        x = c * cell_w\n",
        "        plt.axvline(x=x, color=\"gray\", linestyle=\"--\", linewidth=0.7, zorder=1)\n",
        "\n",
        "    for r in range(SECTOR_ROWS + 1):\n",
        "        y = r * cell_h\n",
        "        plt.axhline(y=y, color=\"gray\", linestyle=\"--\", linewidth=0.7, zorder=1)\n",
        "\n",
        "    # -----------------------------\n",
        "    # Annotate each sector with lifetime\n",
        "    # -----------------------------\n",
        "    sector_index = 0\n",
        "    for r in range(SECTOR_ROWS):\n",
        "        for c in range(SECTOR_COLS):\n",
        "            x_center = c * cell_w + cell_w / 2\n",
        "            y_center = r * cell_h + cell_h / 2\n",
        "\n",
        "            lifetime = sector_lifetimes[sector_index]\n",
        "            text = f\"{lifetime:.0f} rounds\"\n",
        "\n",
        "            plt.text(\n",
        "                x_center, y_center,\n",
        "                text,\n",
        "                ha=\"center\", va=\"center\",\n",
        "                fontsize=9,\n",
        "                fontweight=\"bold\",\n",
        "                color=\"black\",\n",
        "                bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\"),\n",
        "                zorder=4\n",
        "            )\n",
        "\n",
        "            sector_index += 1\n",
        "\n",
        "    # -----------------------------\n",
        "    # Styling\n",
        "    # -----------------------------\n",
        "    plt.xlim(0, AREA_SIZE)\n",
        "    plt.ylim(0, AREA_SIZE)\n",
        "    plt.xlabel(\"X position\")\n",
        "    plt.ylabel(\"Y position\")\n",
        "    plt.title(f\"Sector Lifetimes : {method_name}\")\n",
        "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "diOUnQsr7XFP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "diOUnQsr7XFP",
        "outputId": "942872d7-ecc5-48f2-e537-7c417c14f393"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "for method_name, res in results.items():\n",
        "    rounds = range(1, res[\"last_dead_round\"] + 1)\n",
        "    dead_nodes = [N_NODES - a for a in res[\"alive_nodes_history\"][:res[\"last_dead_round\"]]]\n",
        "    plt.plot(rounds, dead_nodes, label=method_name, linestyle=\"--\", color=colors[list(METHODS.keys()).index(method_name)])\n",
        "plt.xlabel(\"Number of Rounds\")\n",
        "plt.ylabel(\"Dead Nodes\")\n",
        "plt.title(\"Dead Nodes vs Number of Rounds\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fx7cs3F27XFP",
      "metadata": {
        "id": "fx7cs3F27XFP"
      },
      "source": [
        "### Plot 2: Alive Nodes vs Number of Rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AQo0_YPs7XFQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "AQo0_YPs7XFQ",
        "outputId": "2e46069c-c5b5-406a-9416-0c3468cd3b77"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "for method_name, res in results.items():\n",
        "    rounds = range(1, res[\"last_dead_round\"] + 1)\n",
        "    alive_nodes = res[\"alive_nodes_history\"][:res[\"last_dead_round\"]]\n",
        "    plt.plot(rounds, alive_nodes, label=method_name, linestyle=\"--\", color=colors[list(METHODS.keys()).index(method_name)])\n",
        "plt.xlabel(\"Number of Rounds\")\n",
        "plt.ylabel(\"Alive Nodes\")\n",
        "plt.title(\"Alive Nodes vs Number of Rounds\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mz7-8Oxm7XFQ",
      "metadata": {
        "id": "Mz7-8Oxm7XFQ"
      },
      "source": [
        "### Plot 3: Cumulative Throughput vs Number of Rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nia8GTx27XFR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "nia8GTx27XFR",
        "outputId": "2b0dab67-a2a2-48a1-8161-dbe7d9e1a6b4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "for method_name, res in results.items():\n",
        "    rounds = range(1, res[\"last_dead_round\"] + 1)\n",
        "    cumulative_throughput = np.cumsum(res[\"throughput_history\"][:res[\"last_dead_round\"]])\n",
        "    plt.plot(rounds, cumulative_throughput, label=method_name, linestyle=\"--\", color=colors[list(METHODS.keys()).index(method_name)])\n",
        "plt.xlabel(\"Number of Rounds\")\n",
        "plt.ylabel(\"Cumulative Throughput\")\n",
        "plt.title(\"Cumulative Throughput vs Number of Rounds\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0Dobgwr7XFR",
      "metadata": {
        "id": "c0Dobgwr7XFR"
      },
      "source": [
        "### Plot 4: Total Energy Consumed vs Number of Rounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fDj4jFAp7XFR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "fDj4jFAp7XFR",
        "outputId": "538e3497-e6d9-4887-da7c-4029f0339d25"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i, (method_name, res) in enumerate(results.items()):\n",
        "    # total_energy_history[r] must be: sum of remaining energy of ALL nodes at round r\n",
        "    total_E = np.array(res[\"total_energy_history\"][:res[\"last_dead_round\"]])\n",
        "\n",
        "    initial_total_energy = N_NODES * INIT_ENERGY  # sum of all initial energies\n",
        "\n",
        "    # Total energy consumed by all nodes up to each round\n",
        "    total_energy_consumed = initial_total_energy - total_E\n",
        "\n",
        "    rounds = np.arange(1, len(total_energy_consumed) + 1)\n",
        "    plt.plot(\n",
        "        rounds,\n",
        "        total_energy_consumed,\n",
        "        label=method_name,\n",
        "        linestyle=\"--\",\n",
        "        color=colors[i],\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"Number of Rounds\")\n",
        "plt.ylabel(\"Total Energy Consumed (J)\")\n",
        "plt.title(\"Total Energy Consumption vs Number of Rounds\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k0OopsqY7XFR",
      "metadata": {
        "id": "k0OopsqY7XFR"
      },
      "source": [
        "### Plot 5: Total PDR (%) Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bIn2P5P7XFS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "6bIn2P5P7XFS",
        "outputId": "106a6c9c-6306-40fd-c1d9-72183fe65734"
      },
      "outputs": [],
      "source": [
        "total_pdr = {method_name: np.mean(res[\"pdr_percent_history\"][:res[\"last_dead_round\"]])\n",
        "             for method_name, res in results.items()}\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(total_pdr.keys(), total_pdr.values(), color=colors[:len(total_pdr)])\n",
        "plt.ylabel(\"Total PDR (%)\")\n",
        "plt.title(\"Total Packet Delivery Ratio Comparison\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTotal PDR per method:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'Method':<25} {'PDR (%)':>10}\")\n",
        "print(\"-\" * 40)\n",
        "for method, pdr in total_pdr.items():\n",
        "    print(f\"{method:<25} {pdr:>10.2f}\")\n",
        "print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cSm7tpIJ7XFS",
      "metadata": {
        "id": "cSm7tpIJ7XFS"
      },
      "source": [
        "## 9. Results Summary\n",
        "\n",
        "### Node Death Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vlnjQ_Ai7XFS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "vlnjQ_Ai7XFS",
        "outputId": "e29456dc-41fc-4604-a2f8-c40fca67a460"
      },
      "outputs": [],
      "source": [
        "death_table = pd.DataFrame({\n",
        "    \"Method\": list(results.keys()),\n",
        "    \"First Node Death\": [res[\"first_dead_round\"] for res in results.values()],\n",
        "    \"Half Nodes Death\": [res[\"half_dead_round\"] for res in results.values()],\n",
        "    \"Last Node Death\": [res[\"last_dead_round\"] for res in results.values()]\n",
        "})\n",
        "print(\"\\nNode Death Summary Table:\")\n",
        "display(death_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10de7832",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "10de7832",
        "outputId": "868a9e27-748d-4a74-d1db-8287b8636757"
      },
      "outputs": [],
      "source": [
        "death_table = pd.DataFrame({\n",
        "    \"Method\": list(results.keys()),\n",
        "    \"First Node Death\": [res[\"first_dead_round\"] for res in results.values()],\n",
        "    \"Half Nodes Death\": [res[\"half_dead_round\"] for res in results.values()],\n",
        "    \"Last Node Death\": [res[\"last_dead_round\"] for res in results.values()]\n",
        "})\n",
        "\n",
        "# Stable region length (rounds 1 to FND-1; if FND is None, use total ROUNDS)\n",
        "stable_region = []\n",
        "unstable_region = []\n",
        "\n",
        "for method_name, res in results.items():\n",
        "    fnd = res[\"first_dead_round\"]\n",
        "    lnd = res[\"last_dead_round\"]\n",
        "\n",
        "    # If FND not reached, stable region = total simulated rounds\n",
        "    if fnd is None:\n",
        "        stable_len = ROUNDS\n",
        "    else:\n",
        "        stable_len = max(0, fnd - 1)\n",
        "\n",
        "    # Unstable region = from FND to LND\n",
        "    if fnd is None or lnd is None:\n",
        "        unstable_len = 0\n",
        "    else:\n",
        "        unstable_len = max(0, lnd - fnd + 1)\n",
        "\n",
        "    stable_region.append(stable_len)\n",
        "    unstable_region.append(unstable_len)\n",
        "\n",
        "death_table[\"Stable Region (rounds)\"] = stable_region\n",
        "death_table[\"Unstable Region (rounds)\"] = unstable_region\n",
        "\n",
        "print(\"\\nNode Death & Stability Summary Table:\")\n",
        "display(death_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407ba20e",
      "metadata": {
        "id": "407ba20e"
      },
      "outputs": [],
      "source": [
        "def lifetime_until_fraction_dead(alive_history, fraction_dead, total_nodes):\n",
        "    # fraction_dead = 0.75 for 75% dead\n",
        "    threshold_alive = int(np.ceil((1 - fraction_dead) * total_nodes))\n",
        "    for rnd, alive in enumerate(alive_history, start=1):\n",
        "        if alive <= threshold_alive:\n",
        "            return rnd\n",
        "    return None  # not reached within simulated rounds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "764ce418",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "764ce418",
        "outputId": "83db8ad6-4cc3-44e4-f7d4-e5b10c9f2822"
      },
      "outputs": [],
      "source": [
        "lifetime_75_dead = []\n",
        "\n",
        "for method_name, res in results.items():\n",
        "    alive_hist = res[\"alive_nodes_history\"]  # ensure you stored this\n",
        "    round_75 = lifetime_until_fraction_dead(alive_hist, 0.75, N_NODES)\n",
        "    lifetime_75_dead.append(round_75)\n",
        "\n",
        "death_table[\"75% Nodes Dead (round)\"] = lifetime_75_dead\n",
        "\n",
        "display(death_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Saw-aGbilunl",
      "metadata": {
        "id": "Saw-aGbilunl"
      },
      "outputs": [],
      "source": [
        "def plot_routing_snapshot_round_global(\n",
        "    method_name,\n",
        "    rnd,\n",
        "    nodes_pos,\n",
        "    sector_ids,\n",
        "    base_station,\n",
        "    area_size,\n",
        "    sector_rows,\n",
        "    sector_cols\n",
        "):\n",
        "\n",
        "    info = GLOBAL_ROUTING_INFO.get(method_name, {})\n",
        "    chs_dict = info.get(\"chs\", {})\n",
        "    clusters_dict = info.get(\"clusters\", {})\n",
        "    links_dict = info.get(\"links\", {})\n",
        "\n",
        "    chs = chs_dict.get(rnd, [])\n",
        "    clusters = clusters_dict.get(rnd, [])\n",
        "    links = links_dict.get(rnd, [])\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "\n",
        "    # 1) Sector grid\n",
        "    cell_w = area_size / sector_cols\n",
        "    cell_h = area_size / sector_rows\n",
        "    for r in range(sector_rows):\n",
        "        for c in range(sector_cols):\n",
        "            x0 = c * cell_w\n",
        "            y0 = r * cell_h\n",
        "            ax.add_patch(\n",
        "                plt.Rectangle(\n",
        "                    (x0, y0),\n",
        "                    cell_w,\n",
        "                    cell_h,\n",
        "                    fill=False,\n",
        "                    edgecolor=\"lightgray\",\n",
        "                    linewidth=0.7,\n",
        "                    zorder=0\n",
        "                )\n",
        "            )\n",
        "\n",
        "    # 2) Nodes by sector\n",
        "    nodes_pos_arr = np.array(nodes_pos)\n",
        "    ax.scatter(\n",
        "        nodes_pos_arr[:, 0],\n",
        "        nodes_pos_arr[:, 1],\n",
        "        c=sector_ids,\n",
        "        cmap=\"tab10\",\n",
        "        s=40,\n",
        "        edgecolor=\"black\",\n",
        "        zorder=2,\n",
        "        label=\"Nodes\"\n",
        "    )\n",
        "\n",
        "    # 3) CHs\n",
        "    if len(chs) > 0:\n",
        "        ch_positions = nodes_pos_arr[chs]\n",
        "        ax.scatter(\n",
        "            ch_positions[:, 0],\n",
        "            ch_positions[:, 1],\n",
        "            s=120,\n",
        "            marker=\"s\",\n",
        "            color=\"yellow\",\n",
        "            edgecolor=\"red\",\n",
        "            linewidth=1.2,\n",
        "            zorder=3,\n",
        "            label=\"CHs\"\n",
        "        )\n",
        "\n",
        "    # 4) Member -> CH links (from clusters & chs)\n",
        "    for cidx, cluster_nodes in enumerate(clusters):\n",
        "        if not cluster_nodes:\n",
        "            continue\n",
        "        if cidx >= len(chs):\n",
        "            continue\n",
        "        ch_node = chs[cidx]\n",
        "        cx, cy = nodes_pos[ch_node]\n",
        "        for node in cluster_nodes:\n",
        "            if node == ch_node:\n",
        "                continue\n",
        "            nx, ny = nodes_pos[node]\n",
        "            ax.plot(\n",
        "                [nx, cx],\n",
        "                [ny, cy],\n",
        "                color=\"lightgray\",\n",
        "                linewidth=0.6,\n",
        "                alpha=0.9,\n",
        "                zorder=1\n",
        "            )\n",
        "\n",
        "    # 5) Routing links (CH-CH, CH-BS, member-CH as logged)\n",
        "    ch_set = set(chs)\n",
        "    bx, by = base_station\n",
        "\n",
        "    for (src, dst) in links:\n",
        "        if src < 0 or src >= len(nodes_pos):\n",
        "            continue\n",
        "\n",
        "        x1, y1 = nodes_pos[src]\n",
        "\n",
        "        # Decide color and target\n",
        "        if dst == -1:\n",
        "            # CH -> BS\n",
        "            x2, y2 = bx, by\n",
        "            color = \"green\"   # CH–BS\n",
        "            z = 3.0\n",
        "        else:\n",
        "            if dst < 0 or dst >= len(nodes_pos):\n",
        "                continue\n",
        "            x2, y2 = nodes_pos[dst]\n",
        "\n",
        "            if src in ch_set and dst in ch_set:\n",
        "                # CH -> CH (inter-cluster hop)\n",
        "                color = \"red\"\n",
        "                z = 3.0\n",
        "            else:\n",
        "                # other routing link (e.g., member -> CH logged, etc.)\n",
        "                color = \"blue\"\n",
        "                z = 2.5\n",
        "\n",
        "        ax.plot(\n",
        "            [x1, x2],\n",
        "            [y1, y2],\n",
        "            color=color,\n",
        "            linewidth=1.0,\n",
        "            alpha=0.8,\n",
        "            zorder=z\n",
        "        )\n",
        "\n",
        "    # 6) Base station\n",
        "    ax.scatter(\n",
        "        [bx],\n",
        "        [by],\n",
        "        s=180,\n",
        "        marker=\"*\",\n",
        "        color=\"red\",\n",
        "        edgecolor=\"black\",\n",
        "        linewidth=1.2,\n",
        "        zorder=4,\n",
        "        label=\"BS\"\n",
        "    )\n",
        "\n",
        "    # 7) Aesthetics\n",
        "    ax.set_xlim(0, area_size)\n",
        "    ax.set_ylim(0, area_size)\n",
        "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "    ax.set_title(f\"{method_name} – Routing & Clusters – Round {rnd}\")\n",
        "    ax.set_xlabel(\"X (m)\")\n",
        "    ax.set_ylabel(\"Y (m)\")\n",
        "\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, handles))\n",
        "    ax.legend(by_label.values(), by_label.keys(), loc=\"upper right\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jgH5xaill4Vr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "jgH5xaill4Vr",
        "outputId": "e0e1a10c-c08b-45b5-9c1a-25a0ce0fbccc"
      },
      "outputs": [],
      "source": [
        "# After run_proposed() and after simulation:\n",
        "round_to_show = 50\n",
        "method_name = \"RLHC_PROPOSED\"\n",
        "base_station = get_bs_position(round_to_show)\n",
        "\n",
        "plot_routing_snapshot_round_global(\n",
        "    method_name=method_name,\n",
        "    rnd=round_to_show,\n",
        "    nodes_pos=nodes_pos,\n",
        "    sector_ids=sector_ids,\n",
        "    base_station=base_station,\n",
        "    area_size=AREA_SIZE,\n",
        "    sector_rows=SECTOR_ROWS,\n",
        "    sector_cols=SECTOR_COLS\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sSwtF3umm2KA",
      "metadata": {
        "id": "sSwtF3umm2KA"
      },
      "outputs": [],
      "source": [
        "def animate_routing_all_rounds(\n",
        "    method_name,\n",
        "    nodes_pos,\n",
        "    sector_ids,\n",
        "    area_size,\n",
        "    sector_rows,\n",
        "    sector_cols,\n",
        "    rounds,\n",
        "    interval=300  # ms between frames\n",
        "):\n",
        "    \"\"\"\n",
        "    Animate routing and clusters across all rounds for a given method\n",
        "    using GLOBAL_ROUTING_INFO.\n",
        "    \"\"\"\n",
        "    info = GLOBAL_ROUTING_INFO.get(method_name, {})\n",
        "    chs_dict = info.get(\"chs\", {})\n",
        "    clusters_dict = info.get(\"clusters\", {})\n",
        "    links_dict = info.get(\"links\", {})\n",
        "\n",
        "    nodes_pos_arr = np.array(nodes_pos)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "\n",
        "    # -----------------------------\n",
        "    # 1) Draw sector grid (static)\n",
        "    # -----------------------------\n",
        "    cell_w = area_size / sector_cols\n",
        "    cell_h = area_size / sector_rows\n",
        "    for r in range(sector_rows):\n",
        "        for c in range(sector_cols):\n",
        "            x0 = c * cell_w\n",
        "            y0 = r * cell_h\n",
        "            ax.add_patch(\n",
        "                plt.Rectangle(\n",
        "                    (x0, y0),\n",
        "                    cell_w,\n",
        "                    cell_h,\n",
        "                    fill=False,\n",
        "                    edgecolor=\"lightgray\",\n",
        "                    linewidth=0.7,\n",
        "                    zorder=0\n",
        "                )\n",
        "            )\n",
        "\n",
        "    # -----------------------------\n",
        "    # 2) Static node scatter (nodes do not move)\n",
        "    # -----------------------------\n",
        "    node_scatter = ax.scatter(\n",
        "        nodes_pos_arr[:, 0],\n",
        "        nodes_pos_arr[:, 1],\n",
        "        c=sector_ids,\n",
        "        cmap=\"tab10\",\n",
        "        s=40,\n",
        "        edgecolor=\"black\",\n",
        "        zorder=2,\n",
        "        label=\"Nodes\"\n",
        "    )\n",
        "\n",
        "    # -----------------------------\n",
        "    # 3) CH markers (updated per frame)\n",
        "    # -----------------------------\n",
        "    ch_scatter = ax.scatter(\n",
        "        [], [],  # will be updated\n",
        "        s=120,\n",
        "        marker=\"s\",\n",
        "        color=\"yellow\",\n",
        "        edgecolor=\"red\",\n",
        "        linewidth=1.2,\n",
        "        zorder=3,\n",
        "        label=\"CHs\"\n",
        "    )\n",
        "\n",
        "    # -----------------------------\n",
        "    # 4) BS marker (updated per frame)\n",
        "    # -----------------------------\n",
        "    bs_scatter = ax.scatter(\n",
        "        [], [],\n",
        "        s=180,\n",
        "        marker=\"*\",\n",
        "        color=\"red\",\n",
        "        edgecolor=\"black\",\n",
        "        linewidth=1.2,\n",
        "        zorder=4,\n",
        "        label=\"BS\"\n",
        "    )\n",
        "\n",
        "    # -----------------------------\n",
        "    # 5) Line containers for:\n",
        "    #    - member→CH links (intra-cluster)\n",
        "    #    - routing links (CH-CH, CH-BS, member-CH as logged)\n",
        "    # -----------------------------\n",
        "    intra_lines = []   # member -> CH (light gray)\n",
        "    route_lines = []   # routing links (blue)\n",
        "\n",
        "    # Setup axes\n",
        "    ax.set_xlim(0, area_size)\n",
        "    ax.set_ylim(0, area_size)\n",
        "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "    ax.set_xlabel(\"X (m)\")\n",
        "    ax.set_ylabel(\"Y (m)\")\n",
        "    title_text = ax.set_title(\"\")\n",
        "\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, handles))\n",
        "    ax.legend(by_label.values(), by_label.keys(), loc=\"upper right\")\n",
        "\n",
        "    # -----------------------------\n",
        "    # 6) Update function for each frame\n",
        "    # -----------------------------\n",
        "    def init():\n",
        "        # nothing else to init; lines will be created in first update\n",
        "        return node_scatter, ch_scatter, bs_scatter\n",
        "\n",
        "    def update(frame_idx):\n",
        "        rnd = frame_idx + 1  # assuming rounds start at 1\n",
        "        if rnd > rounds:\n",
        "            rnd = rounds\n",
        "\n",
        "        # Get data for this round\n",
        "        chs = chs_dict.get(rnd, [])\n",
        "        clusters = clusters_dict.get(rnd, [])\n",
        "        links = links_dict.get(rnd, [])\n",
        "        print(f\"Updating Frame={frame_idx}, Round={rnd}, CHs={len(chs)}, Links={len(links)}\")\n",
        "\n",
        "        # Update title\n",
        "        title_text.set_text(f\"{method_name} – Routing & Clusters – Round {rnd}\")\n",
        "\n",
        "        # Update CH scatter\n",
        "        if len(chs) > 0:\n",
        "            ch_pos = nodes_pos_arr[chs]\n",
        "            ch_scatter.set_offsets(ch_pos)\n",
        "        else:\n",
        "            ch_scatter.set_offsets(np.empty((0, 2)))\n",
        "\n",
        "        # Update BS position\n",
        "        bx, by = get_bs_position(rnd)\n",
        "        bs_scatter.set_offsets(np.array([[bx, by]]))\n",
        "\n",
        "        # Clear old lines\n",
        "        for ln in intra_lines:\n",
        "            ln.remove()\n",
        "        intra_lines.clear()\n",
        "\n",
        "        for ln in route_lines:\n",
        "            ln.remove()\n",
        "        route_lines.clear()\n",
        "\n",
        "        # Draw member -> CH (from clusters & chs) in light gray\n",
        "        for cidx, cluster_nodes in enumerate(clusters):\n",
        "            if not cluster_nodes:\n",
        "                continue\n",
        "            if cidx >= len(chs):\n",
        "                continue\n",
        "            ch_node = chs[cidx]\n",
        "            cx, cy = nodes_pos[ch_node]\n",
        "            for node in cluster_nodes:\n",
        "                if node == ch_node:\n",
        "                    continue\n",
        "                nx, ny = nodes_pos[node]\n",
        "                ln, = ax.plot(\n",
        "                    [nx, cx],\n",
        "                    [ny, cy],\n",
        "                    color=\"lightgray\",\n",
        "                    linewidth=0.6,\n",
        "                    alpha=0.9,\n",
        "                    zorder=1\n",
        "                )\n",
        "                intra_lines.append(ln)\n",
        "\n",
        "        # ---------------------------------------\n",
        "        # Draw routing links with different colors\n",
        "        #   - CH -> BS : green\n",
        "        #   - CH -> CH : red (inter-cluster)\n",
        "        #   - others   : blue (default)\n",
        "        # ---------------------------------------\n",
        "        ch_set = set(chs)\n",
        "\n",
        "        for (src, dst) in links:\n",
        "            if src < 0 or src >= len(nodes_pos):\n",
        "                continue\n",
        "            x1, y1 = nodes_pos[src]\n",
        "\n",
        "            # Determine target position and link type\n",
        "            if dst == -1:\n",
        "                # CH -> BS\n",
        "                x2, y2 = bx, by\n",
        "                color = \"green\"\n",
        "                z = 3.0\n",
        "            else:\n",
        "                if dst < 0 or dst >= len(nodes_pos):\n",
        "                    continue\n",
        "                x2, y2 = nodes_pos[dst]\n",
        "\n",
        "                if src in ch_set and dst in ch_set:\n",
        "                    # CH -> CH (inter-cluster hop)\n",
        "                    color = \"red\"\n",
        "                    z = 3.0\n",
        "                else:\n",
        "                    # other routing link (e.g., member -> CH logged, etc.)\n",
        "                    color = \"blue\"\n",
        "                    z = 2.5\n",
        "\n",
        "            ln, = ax.plot(\n",
        "                [x1, x2],\n",
        "                [y1, y2],\n",
        "                color=color,\n",
        "                linewidth=1.2,\n",
        "                alpha=0.9,\n",
        "                zorder=z\n",
        "            )\n",
        "            route_lines.append(ln)\n",
        "\n",
        "        return node_scatter, ch_scatter, bs_scatter, title_text\n",
        "\n",
        "\n",
        "    # -----------------------------\n",
        "    # 7) Create animation\n",
        "    # -----------------------------\n",
        "    ani = animation.FuncAnimation(\n",
        "        fig,\n",
        "        update,\n",
        "        frames=rounds,\n",
        "        init_func=init,\n",
        "        interval=interval,\n",
        "        blit=False,  # easier with multiple artists\n",
        "        repeat=True\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    # plt.show()\n",
        "\n",
        "    return ani\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wEiYN-O9m4AB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEiYN-O9m4AB",
        "outputId": "799c5783-ab18-4713-bcd4-d265ed576754"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "mpl.rcParams['animation.embed_limit'] = 200  # in MB\n",
        "\n",
        "ani = animate_routing_all_rounds(\n",
        "    method_name=\"RLHC_PROPOSED\",\n",
        "    nodes_pos=nodes_pos,\n",
        "    sector_ids=sector_ids,\n",
        "    area_size=AREA_SIZE,\n",
        "    sector_rows=SECTOR_ROWS,\n",
        "    sector_cols=SECTOR_COLS,\n",
        "    rounds=ROUNDS,\n",
        "    interval=300\n",
        ")\n",
        "\n",
        "HTML(ani.to_jshtml())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
